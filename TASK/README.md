# PraktickÃ© cviÄenÃ­ - Lekce 6: Fine-tuning jazykovÃ©ho modelu
## [AI Developer]

**PoÄet bodÅ¯:** 100  
**Deadline:** 17.6.2025

---

## ğŸ“‹ ZadÃ¡nÃ­ Ãºkolu

Vyberte si metodu fine-tuningu modelu podle svÃ©ho zamÃ½Å¡lenÃ©ho pouÅ¾itÃ­ â€“ buÄ pomocÃ­ OpenAI API (napÅ™. doladÄ›nÃ­ GPT-4) nebo s vyuÅ¾itÃ­m Hugging Face (napÅ™. transformers a PEFT). ProveÄte srovnÃ¡nÃ­ odpovÄ›dÃ­ modelu pÅ™ed a po fine-tuningu a vyhodnoÅ¥te zmÄ›ny pomocÃ­ benchmarkingu.

**Forma odevzdÃ¡nÃ­:** VypracovanÃ½ Ãºkol odevzdejte ve formÄ› tabulky (excel, Google sheet), screenshotÅ¯ nebo PDF souboru obsahujÃ­cÃ­ho vÅ¡echny odpovÄ›di a vaÅ¡e bodovÃ© ohodnocenÃ­ (benchmarking). Nahrajte soubor na Google Classroom.

---

## ğŸ¯ CÃ­l projektu

CÃ­lem projektu bylo vytvoÅ™it fine-tuning dataset pro jazykovÃ½ model, kterÃ½ by napodoboval charakteristickÃ½ styl komunikace Andreje BabiÅ¡e - ÄeskÃ©ho politika a podnikatele. Model mÄ›l bÃ½t schopen generovat satirickÃ© odpovÄ›di ve stylu "babÃ­Å¡ovÅ¡tiny" - charakteristickÃ©ho jazykovÃ©ho stylu s mluvenou ÄeÅ¡tinou, slovensko-ÄeskÃ½mi odchylkami a specifickÃ½mi rÃ©torickÃ½mi prvky.

---

## ğŸ”„ Metodologie a implementace

### 1. PoÄÃ¡teÄnÃ­ pÅ™Ã­stup a jeho problÃ©my

**PrvnÃ­ pokus:** RuÄnÃ­ sbÄ›r dat
- StÃ¡hnuty vÅ¡echny projevy Andreje BabiÅ¡e z poslaneckÃ© snÄ›movny
- ZÃ­skÃ¡ny rozhovory z obdobÃ­ pÅ¯sobenÃ­ na ministerstvu financÃ­
- ShromÃ¡Å¾dÄ›ny ÄlÃ¡nky z bulvÃ¡rnÃ­ch plÃ¡tkÅ¯ (ParlamentnÃ­ listy)
- **ProblÃ©m:** Mix satirickÃ½ch vÃ½rokÅ¯ a pÅ™edpÅ™ipravenÃ½ch textÅ¯ byl nevyrovnanÃ½, konzistentnost nÃ¡zorÅ¯ byla problematickÃ¡ (data z roku 2013,2017,2021 jdou nÃ¡zorovÄ› proti sobÄ›)
- **VÃ½sledek:** RuÄnÃ­ tÅ™Ã­dÄ›nÃ­ se stalo neefektivnÃ­ a ÄasovÄ› nÃ¡roÄnÃ©

### 2. PÅ™echod k LLM-based metodÄ›

**DÅ¯vod zmÄ›ny:** LLM nedokÃ¡Å¾Ã­ zpracovat sloÅ¾itÄ›jÅ¡Ã­ zadÃ¡nÃ­ najednou
**Å˜eÅ¡enÃ­:** Rozklad procesu na menÅ¡Ã­, detailnÃ­ kroky
- Simplifikace zadÃ¡nÃ­
- Rozklad na tvorbu Å¡ablon a nÃ¡slednÃ© generovÃ¡nÃ­ datasetu
- PostupnÃ© zpracovÃ¡nÃ­ v dÃ¡vkÃ¡ch

---

## ğŸ› ï¸ ImplementaÄnÃ­ kroky

### Krok 1: VytvoÅ™enÃ­ Å¡ablon (Templates)

**Soubor:** `TASK/LLM.Outline.CreateTemplates.md`
- **Ãškol:** Vygenerovat 400 originÃ¡lnÃ­ch Å¡ablon vÃ½rokÅ¯ ve stylu Andreje BabiÅ¡e
- **Model:** GPT-o3 (GPT-4.5 se ukÃ¡zal jako nevhodnÃ½ - nepochopil zadÃ¡nÃ­)
- **ZajÃ­mavost:** GPT-o3 si vytvoÅ™il Python skripty pro brute-force sklÃ¡dÃ¡nÃ­ slov
- **VÃ½stup:** Å ablony s placeholdery pro rÅ¯znÃ© kategorie (tÃ©ma, nepÅ™Ã­tel, Äinnost, kritika, atd.)

**KlÃ­ÄovÃ© placeholdery:**
- `{tema}` - inflace, vÃ¡lka, dÅ¯chody, klima, oÄkovÃ¡nÃ­, danÄ›
- `{nepritel}` - Brusel, PirÃ¡ti, Fiala, novinÃ¡Å™i, opozice
- `{cinnost}` - makal, pomÃ¡hal lidem, budoval stÃ¡t, ruÅ¡il poplatky
- `{kritika}` - kradou, sabotujou nÃ¡s, jenom Å™eÄnÃ­
- `{emotivni_vyraz}` - to je Å¡Ã­lenÃ½!, kampÃ¡Ã¡Åˆ!, tragÃ©dyje!

### Krok 2: GenerovÃ¡nÃ­ odpovÄ›dÃ­

**Soubor:** `TASK/LLM.CreateAnswers.systemPrompt.md`
- **Ãškol:** Nahradit placeholdery v Å¡ablonÃ¡ch konkrÃ©tnÃ­mi hodnotami
- **ZpracovÃ¡nÃ­:** Po 300 Å¡ablonÃ¡ch v dÃ¡vkÃ¡ch
- **Pravidla:** 
  - 15% pravdÄ›podobnost jazykovÃ© chyby
  - RovnomÄ›rnÃ½ mix 5 stylÅ¯ (emocionÃ¡lnÃ­ vÃ½levy, odmÃ­tavÃ½ postoj, domÃ½Å¡livost, chaotickÃ¡ logika, ironie)
  - ZachovÃ¡nÃ­ autentickÃ©ho stylu "babÃ­Å¡ovÅ¡tiny"

### Krok 3: VytvoÅ™enÃ­ dialogÅ¯

**Soubor:** `TASK/LLM.CreateDialogue.systemPrompt.md`
- **Ãškol:** Generovat korespondujÃ­cÃ­ novinÃ¡Å™skÃ© otÃ¡zky k odpovÄ›dÃ­m
- **FormÃ¡t:** JSONL s pÃ¡ry otÃ¡zka-odpovÄ›Ä
- **Styl:** ProfesionÃ¡lnÃ­ redaktor v rozhovoru

### Krok 4: AutomatizovanÃ© zpracovÃ¡nÃ­

**Skript:** `generate_qa_dataset.py`
- **Funkce:** ZpracovÃ¡nÃ­ vÅ¡ech batch souborÅ¯
- **VÃ½stup:** StrukturovanÃ© QA pÃ¡ry pro fine-tuning
- **Kontrola:** VÃ½poÄet nÃ¡kladÅ¯ pomocÃ­ tiktokenizer

**Skript:** `generate_answers.py`
- **Funkce:** GenerovÃ¡nÃ­ odpovÄ›dÃ­ z Å¡ablon
- **Optimalizace:** DÃ¡vkovÃ© zpracovÃ¡nÃ­ pro Ãºsporu nÃ¡kladÅ¯

### Krok 5: SlouÄenÃ­ dat

**Skript:** `dataset_merger.py`
- **Ãškol:** SlouÄit vÅ¡echny vygenerovanÃ© dÃ¡vky
- **VÃ½stup:** `data/all.jsonl` - kompletnÃ­ dataset

### Krok 6: Moderace obsahu

**Skript:** `moderate_training_data.py`
- **Ãškol:** Kontrola obsahu pomocÃ­ OpenAI Moderation API
- **Endpoint:** `https://api.openai.com/v1/moderations`
- **ProblÃ©m:** Dataset byl zablokovÃ¡n moderacÃ­
- **Chyba:** "The job failed due to an invalid validation file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies"

---

## ğŸ“Š Struktura projektu

### AdresÃ¡Å™e a soubory:

```
talklike.llm/
â”œâ”€â”€ TASK/                          # ZadÃ¡nÃ­ a Å¡ablony
â”‚   â”œâ”€â”€ babis_templates_400.json   # VygenerovanÃ© Å¡ablony
â”‚   â”œâ”€â”€ LLM.Outline.CreateTemplates.md
â”‚   â”œâ”€â”€ LLM.CreateAnswers.systemPrompt.md
â”‚   â”œâ”€â”€ LLM.CreateDialogue.systemPrompt.md
â”‚   â””â”€â”€ LLM.finetunning.systemPrompt.json
â”œâ”€â”€ generated_batches/             # MezivÃ½stupy
â”‚   â”œâ”€â”€ batch_01_babis_output.jsonl
â”‚   â”œâ”€â”€ content/                   # Obsah dÃ¡vek
â”‚   â”œâ”€â”€ responses/                 # OdpovÄ›di LLM
â”‚   â””â”€â”€ invalid/                   # NeplatnÃ© vÃ½stupy
â”œâ”€â”€ final/                         # FinÃ¡lnÃ­ QA dataset
â”‚   â”œâ”€â”€ batch_01_babis_output_qa.jsonl
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                          # SlouÄenÃ¡ data
â”‚   â”œâ”€â”€ all.jsonl                  # KompletnÃ­ dataset
â”‚   â”œâ”€â”€ moderated_training_data.jsonl
â”‚   â””â”€â”€ moderated_training_data_report.txt
â””â”€â”€ Skripty pro zpracovÃ¡nÃ­
    â”œâ”€â”€ generate_qa_dataset.py
    â”œâ”€â”€ generate_answers.py
    â”œâ”€â”€ dataset_merger.py
    â”œâ”€â”€ moderate_training_data.py
    â””â”€â”€ llm_cost_calculator.py
```

---

## ğŸ’° NÃ¡klady a optimalizace

### VÃ½poÄet nÃ¡kladÅ¯:
- **NÃ¡stroj:** `llm_cost_calculator.py` a `openai_cost_calculator.py`
- **Metoda:** PouÅ¾itÃ­ tiktokenizer pro pÅ™esnÃ½ vÃ½poÄet tokenÅ¯
- **Optimalizace:** DÃ¡vkovÃ© zpracovÃ¡nÃ­ pro minimalizaci nÃ¡kladÅ¯

### Logy a monitoring:
- **AdresÃ¡Å™:** `logs/` - detailnÃ­ logy vÅ¡ech operacÃ­
- **Soubor:** `moderation.log` - vÃ½sledky moderace

---

## ğŸ“ˆ VÃ½sledky

### VytvoÅ™enÃ½ dataset:
- **CelkovÃ½ poÄet pÃ¡rÅ¯:** 3,000 QA pÃ¡rÅ¯ v `data/all.jsonl`
- **FormÃ¡t:** JSONL s konverzaÄnÃ­mi pÃ¡ry (system, user, assistant)
- **Struktura:** KaÅ¾dÃ¡ odpovÄ›Ä konÄÃ­ "Andrej BabiÅ¡" jako podpis

### Charakteristika obsahu:
- **Styl:** MluvenÃ¡ ÄeÅ¡tina s "babÃ­Å¡ovÅ¡tinou"
- **TÃ©mata:** Politika, ekonomika, rodina, podnikÃ¡nÃ­
- **TÃ³n:** SatirickÃ½, emotivnÃ­, sebestÅ™ednÃ½
- **JazykovÃ© prvky:** Slovensko-ÄeskÃ© odchylky, zÃ¡mÄ›rnÃ© chyby

---

## ğŸ“ ZÃ¡vÄ›r

Projekt ÃºspÄ›Å¡nÄ› demonstroval kompletnÃ­ workflow pro vytvoÅ™enÃ­ fine-tuning datasetu pomocÃ­ LLM. KlÃ­ÄovÃ½m poznatkem bylo, Å¾e sloÅ¾itÃ© zadÃ¡nÃ­ je nutnÃ© rozdÄ›lit na menÅ¡Ã­, detailnÃ­ kroky. VytvoÅ™enÃ½ dataset obsahuje 3,000 konverzaÄnÃ­ch pÃ¡rÅ¯ pÅ™ipravenÃ½ch pro fine-tuning, i kdyÅ¾ byl nÃ¡slednÄ› zablokovÃ¡n OpenAI moderacÃ­ kvÅ¯li satirickÃ©mu obsahu.

**SilnÃ© strÃ¡nky:** KompletnÃ­ implementace, kvalitnÃ­ dataset, dobÅ™e strukturovanÃ½ kÃ³d
**Oblasti pro zlepÅ¡enÃ­:** Å˜eÅ¡enÃ­ moderace obsahu, alternativnÃ­ pÅ™Ã­stupy k fine-tuningu
