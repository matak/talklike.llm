#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HlavnÃ­ benchmarking script pro TalkLike.LLM
SrovnÃ¡vÃ¡ vÃ½kon modelu pÅ™ed a po fine-tuningu
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# Detekce, zda je skript spouÅ¡tÄ›n z rootu nebo z adresÃ¡Å™e 3_benchmarking
current_file = Path(__file__)
if current_file.parent.name == "3_benchmarking":
    # SpouÅ¡tÄ›no z rootu: python 3_benchmarking/run_benchmark.py
    project_root = current_file.parent.parent
    benchmark_dir = current_file.parent
    # ZÅ¯stÃ¡vÃ¡me v root adresÃ¡Å™i
else:
    # SpouÅ¡tÄ›no z adresÃ¡Å™e 3_benchmarking
    project_root = current_file.parent.parent
    benchmark_dir = current_file.parent

# PÅ™idÃ¡nÃ­ rootu projektu do path pro import modulÅ¯
sys.path.insert(0, str(project_root))

# Import setup_environment z rootu
from setup_environment import setup_environment
setup_environment()

# PÅ™idÃ¡nÃ­ benchmarking adresÃ¡Å™e do path pro import modulÅ¯
sys.path.insert(0, str(benchmark_dir))

from evaluate_style import evaluate_babis_style, evaluate_all_responses
from compare_models import compare_models
from generate_responses import generate_responses
from create_benchmark_dataset import create_benchmark_dataset
from generate_report import generate_final_report

def setup_directories():
    """VytvoÅ™Ã­ potÅ™ebnÃ© adresÃ¡Å™e pro vÃ½sledky"""
    directories = [
        "results/before_finetune",
        "results/after_finetune", 
        "results/comparison",
        "results/reports",
        "results/visualizations"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… VytvoÅ™en adresÃ¡Å™: {directory}")

def main():
    """HlavnÃ­ benchmarking pipeline"""
    print("ğŸš€ SpouÅ¡tÃ­m benchmarking pipeline pro TalkLike.LLM")
    print("=" * 60)
    
    start_time = datetime.now()
    
    # 1. NastavenÃ­ adresÃ¡Å™Å¯
    print("\nğŸ“ Nastavuji adresÃ¡Å™e...")
    setup_directories()
    
    # 2. VytvoÅ™enÃ­ testovacÃ­ch dat
    print("\nğŸ“‹ VytvÃ¡Å™Ã­m benchmark dataset...")
    create_benchmark_dataset()
    
    # 3. GenerovÃ¡nÃ­ odpovÄ›dÃ­ pÅ™ed fine-tuningem
    print("\nğŸ¤– Generuji odpovÄ›di pÅ™ed fine-tuningem...")
    generate_responses("base", "results/before_finetune/")
    
    # 4. GenerovÃ¡nÃ­ odpovÄ›dÃ­ po fine-tuningem
    print("\nğŸ¤– Generuji odpovÄ›di po fine-tuningem...")
    generate_responses("finetuned", "results/after_finetune/")
    
    # 5. SrovnÃ¡nÃ­ modelÅ¯
    print("\nğŸ“Š SrovnÃ¡vÃ¡m modely...")
    comparison_results = compare_models()
    
    # 6. Evaluace stylu
    print("\nğŸ¯ Evaluuji styl...")
    style_results = evaluate_all_responses()
    
    # 7. Kombinace vÅ¡ech vÃ½sledkÅ¯ pro report
    print("\nğŸ“‹ Generuji finÃ¡lnÃ­ report...")
    all_results = {
        "model_comparison": comparison_results,
        "style_evaluation": style_results
    }
    generate_final_report(all_results)
    
    # 8. VÃ½pis vÃ½sledkÅ¯
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 60)
    print("âœ… Benchmarking ÃºspÄ›Å¡nÄ› dokonÄen!")
    print(f"â±ï¸  CelkovÃ½ Äas: {duration}")
    print(f"ğŸ“ VÃ½sledky v: results/")
    print(f"ğŸ“Š Reporty v: results/reports/")
    print(f"ğŸ“ˆ Vizualizace v: results/visualizations/")
    print("=" * 60)

if __name__ == "__main__":
    main() 