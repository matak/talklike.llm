#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GenerovÃ¡nÃ­ odpovÄ›dÃ­ pro benchmarking TalkLike.LLM
Simuluje odpovÄ›di pÅ™ed a po fine-tuningu
"""

import json
import os
import random
from datetime import datetime
from typing import List, Dict

def generate_mock_response(question: str, model_type: str) -> str:
    """Generuje mock odpovÄ›Ä pro testovacÃ­ ÃºÄely"""
    
    # ZÃ¡kladnÃ­ BabiÅ¡ovy frÃ¡ze
    babis_phrases = [
        "Hele,", "To je skandÃ¡l!", "JÃ¡ makÃ¡m", "Opozice krade", 
        "V Bruselu", "Moje rodina", "JÃ¡ jsem to neÄetl"
    ]
    
    # SlovenskÃ© odchylky
    slovak_phrases = [
        "sme", "som", "makÃ¡me", "centralizÃ¡cia", "efektivizÃ¡cia"
    ]
    
    # PÅ™irovnÃ¡nÃ­
    comparisons = [
        "jak kdyÅ¾ krÃ¡va hraje na klavÃ­r",
        "jak kdyÅ¾ dÃ­tÄ› Å™Ã­dÃ­ tank",
        "jak kdyÅ¾ slepice hraje Å¡achy",
        "jak kdyÅ¾ ryba jezdÃ­ na kole"
    ]
    
    # EmotivnÃ­ vÃ½razy
    emotional_phrases = [
        "to je Å¡Ã­lenÃ½!", "tragÃ©dyje!", "kampÃ¡Ã¡Åˆ!", "hroznÃ©!"
    ]
    
    if model_type == "base":
        # PÅ™ed fine-tuningem - mÃ©nÄ› BabiÅ¡Å¯v styl
        responses = [
            f"Inflace je vÃ¡Å¾nÃ½ problÃ©m, kterÃ½ postihuje vÅ¡echny obÄany.",
            f"Opozice mÃ¡ prÃ¡vo na kritiku, ale mÄ›la by bÃ½t konstruktivnÃ­.",
            f"Rodina je dÅ¯leÅ¾itÃ¡ hodnota pro kaÅ¾dÃ©ho ÄlovÄ›ka.",
            f"PodnikÃ¡nÃ­ vyÅ¾aduje zodpovÄ›dnÃ½ pÅ™Ã­stup a dodrÅ¾ovÃ¡nÃ­ pravidel.",
            f"EvropskÃ© instituce majÃ­ svÃ© mÃ­sto v modernÃ­ spoleÄnosti."
        ]
        return random.choice(responses)
    
    else:  # finetuned
        # Po fine-tuningem - autentickÃ½ BabiÅ¡Å¯v styl
        base_response = random.choice(babis_phrases)
        
        # PÅ™idÃ¡nÃ­ slovenskÃ© odchylky (15% pravdÄ›podobnost)
        if random.random() < 0.15:
            base_response += f" {random.choice(slovak_phrases)}"
        
        # PÅ™idÃ¡nÃ­ pÅ™irovnÃ¡nÃ­ (30% pravdÄ›podobnost)
        if random.random() < 0.3:
            base_response += f" {random.choice(comparisons)}"
        
        # PÅ™idÃ¡nÃ­ emotivnÃ­ho vÃ½razu (40% pravdÄ›podobnost)
        if random.random() < 0.4:
            base_response += f" {random.choice(emotional_phrases)}"
        
        # ZakonÄenÃ­ podpisem
        base_response += " Andrej BabiÅ¡"
        
        return base_response

def generate_responses(model_type: str, output_dir: str):
    """Generuje odpovÄ›di pro danÃ½ typ modelu"""
    
    print(f"ğŸ¤– Generuji odpovÄ›di pro model: {model_type}")
    
    # NaÄtenÃ­ benchmark datasetu
    if os.path.exists("results/benchmark_dataset.json"):
        with open("results/benchmark_dataset.json", "r", encoding="utf-8") as f:
            dataset = json.load(f)
        
        questions = dataset.get("questions", [])
    else:
        # Fallback na zÃ¡kladnÃ­ otÃ¡zky
        questions = [
            {"id": "Q1", "question": "Pane BabiÅ¡i, jak hodnotÃ­te souÄasnou inflaci?"},
            {"id": "Q2", "question": "Co si myslÃ­te o opozici?"},
            {"id": "Q3", "question": "Jak se vÃ¡m daÅ™Ã­ s rodinou?"},
            {"id": "Q4", "question": "MÅ¯Å¾ete vysvÄ›tlit vaÅ¡i roli v tÃ© chemiÄce?"},
            {"id": "Q5", "question": "Jak vnÃ­mÃ¡te reakce Bruselu na ekonomickou situaci v ÄŒesku?"}
        ]
    
    responses = []
    
    for question in questions:
        response = generate_mock_response(question["question"], model_type)
        
        responses.append({
            "id": question["id"],
            "question": question["question"],
            "response": response,
            "model_type": model_type,
            "timestamp": datetime.now().isoformat()
        })
    
    # UloÅ¾enÃ­ odpovÄ›dÃ­
    output_file = os.path.join(output_dir, "responses.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(responses, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… VygenerovÃ¡no {len(responses)} odpovÄ›dÃ­")
    print(f"ğŸ’¾ UloÅ¾eno: {output_file}")
    
    # VÃ½pis nÄ›kolika pÅ™Ã­kladÅ¯
    print(f"\nğŸ“ PÅ™Ã­klady odpovÄ›dÃ­ ({model_type}):")
    for i, resp in enumerate(responses[:3]):
        print(f"   {i+1}. {resp['question']}")
        print(f"      â†’ {resp['response']}")
        print()
    
    return responses

def generate_real_responses(model_type: str, output_dir: str):
    """Generuje skuteÄnÃ© odpovÄ›di pomocÃ­ LLM (pro budoucÃ­ pouÅ¾itÃ­)"""
    
    # TODO: Implementovat skuteÄnÃ© generovÃ¡nÃ­ pomocÃ­ OpenAI API nebo Hugging Face
    # ProzatÃ­m pouÅ¾Ã­vÃ¡me mock odpovÄ›di
    
    print(f"âš ï¸  SkuteÄnÃ© generovÃ¡nÃ­ pomocÃ­ LLM nenÃ­ implementovÃ¡no")
    print(f"   PouÅ¾Ã­vÃ¡m mock odpovÄ›di pro {model_type}")
    
    return generate_responses(model_type, output_dir)

if __name__ == "__main__":
    # Test generovÃ¡nÃ­ odpovÄ›dÃ­
    print("ğŸ§ª Test generovÃ¡nÃ­ odpovÄ›dÃ­...")
    
    # Test pÅ™ed fine-tuningem
    base_responses = generate_responses("base", "results/before_finetune/")
    
    # Test po fine-tuningem
    finetuned_responses = generate_responses("finetuned", "results/after_finetune/")
    
    print(f"\nâœ… Test dokonÄen:")
    print(f"   PÅ™ed fine-tuningem: {len(base_responses)} odpovÄ›dÃ­")
    print(f"   Po fine-tuningem: {len(finetuned_responses)} odpovÄ›dÃ­") 