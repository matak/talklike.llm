# ğŸ¯ KompletnÃ­ Å™eÅ¡enÃ­ Fine-tuning projektu

## ğŸ“‹ PÅ™ehled

Tento projekt implementuje **kompletnÃ­ Å™eÅ¡enÃ­ fine-tuningu jazykovÃ©ho modelu** rozdÄ›lenÃ© na **3 hlavnÃ­ ÄÃ¡sti** podle zadÃ¡nÃ­ Ãºkolu:

1. **ğŸ“Š PÅ™Ã­prava datasetu** - VytvoÅ™enÃ­ trÃ©novacÃ­ch dat
2. **ğŸ‹ï¸ Fine-tuning modelu** - DoladÄ›nÃ­ jazykovÃ©ho modelu  
3. **ğŸ“ˆ Benchmarking** - SrovnÃ¡nÃ­ pÅ™ed a po fine-tuningu

---

## ğŸš€ RychlÃ½ start

### SpuÅ¡tÄ›nÃ­ celÃ©ho workflow:

```bash
# KompletnÃ­ pipeline (doporuÄeno)
python run_complete_workflow.py --complete

# Nebo interaktivnÄ›
python run_complete_workflow.py
```

### SpuÅ¡tÄ›nÃ­ jednotlivÃ½ch ÄÃ¡stÃ­:

```bash
# 1. PÅ™Ã­prava datasetu
./scripts/prepare_dataset.sh

# 2. Fine-tuning modelu
./scripts/run_finetune.sh

# 3. Benchmarking
./scripts/run_benchmarking.sh
```

---

## ğŸ“Š ÄŒÃST 1: PÅ™Ã­prava datasetu

### ğŸ¯ CÃ­l
VytvoÅ™it kvalitnÃ­ dataset pro fine-tuning modelu ve stylu Andreje BabiÅ¡e.

### ğŸ“ Struktura
```
dataset_preparation/
â”œâ”€â”€ templates/              # Å ablony s placeholdery
â”œâ”€â”€ generators/             # GenerÃ¡tory dat
â”œâ”€â”€ moderation/             # Moderace obsahu
â”œâ”€â”€ data/                   # MezivÃ½stupy
â””â”€â”€ run_dataset_preparation.py  # HlavnÃ­ skript
```

### ğŸ”§ Implementace

#### Krok 1: VytvoÅ™enÃ­ Å¡ablon
- 400 Å¡ablon s placeholdery pro rÅ¯znÃ© kategorie
- TÃ©mata: inflace, vÃ¡lka, dÅ¯chody, klima, oÄkovÃ¡nÃ­, danÄ›
- NepÅ™Ã¡telÃ©: Brusel, PirÃ¡ti, Fiala, novinÃ¡Å™i, opozice

#### Krok 2: GenerovÃ¡nÃ­ odpovÄ›dÃ­
- NahrazenÃ­ placeholderÅ¯ konkrÃ©tnÃ­mi hodnotami
- 15% pravdÄ›podobnost jazykovÃ© chyby
- Mix 5 stylÅ¯ (emocionÃ¡lnÃ­, odmÃ­tavÃ½, domÃ½Å¡livÃ½, chaotickÃ½, ironickÃ½)

#### Krok 3: VytvoÅ™enÃ­ dialogÅ¯
- GenerovÃ¡nÃ­ novinÃ¡Å™skÃ½ch otÃ¡zek k odpovÄ›dÃ­m
- FormÃ¡t: JSONL s pÃ¡ry otÃ¡zka-odpovÄ›Ä

#### Krok 4: Moderace obsahu
- Kontrola pomocÃ­ OpenAI Moderation API
- Filtrace nevhodnÃ©ho obsahu

#### Krok 5: FinÃ¡lnÃ­ dataset
- StrukturovanÃ½ formÃ¡t pro fine-tuning
- 3,000 QA pÃ¡rÅ¯ v `data/all.jsonl`

### ğŸ“Š VÃ½stup
- **Dataset:** `data/all.jsonl` (3,000 QA pÃ¡rÅ¯)
- **FormÃ¡t:** JSONL s konverzaÄnÃ­mi pÃ¡ry (system, user, assistant)
- **Struktura:** KaÅ¾dÃ¡ odpovÄ›Ä konÄÃ­ "Andrej BabiÅ¡" jako podpis

---

## ğŸ‹ï¸ ÄŒÃST 2: Fine-tuning modelu

### ğŸ¯ CÃ­l
Fine-tune jazykovÃ½ model na pÅ™ipravenÃ©m datasetu pomocÃ­ LoRA.

### ğŸ“ Struktura
```
fine_tuning/
â”œâ”€â”€ models/                 # Fine-tuning skripty
â”œâ”€â”€ configs/                # Konfigurace
â”œâ”€â”€ utils/                  # PomocnÃ© funkce
â”œâ”€â”€ scripts/                # Bash skripty
â””â”€â”€ run_finetune.py         # HlavnÃ­ skript
```

### ğŸ”§ Implementace

#### Krok 1: PÅ™Ã­prava prostÅ™edÃ­
- Instalace zÃ¡vislostÃ­
- NastavenÃ­ tokenÅ¯ (HF_TOKEN, WANDB_API_KEY)
- Kontrola GPU

#### Krok 2: NaÄtenÃ­ modelu
- Base model: Meta-Llama-3-8B-Instruct
- Tokenizer s podporou chat formÃ¡tu
- AutomatickÃ¡ detekce device (GPU/CPU)

#### Krok 3: Konfigurace LoRA
- Rank (r): 16
- Alpha: 32
- Dropout: 0.1
- Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj

#### Krok 4: PÅ™Ã­prava dat
- Tokenizace datasetu
- RozdÄ›lenÃ­ na train/validation (90/10)
- Data collator pro language modeling

#### Krok 5: TrÃ©novÃ¡nÃ­
- Epochs: 3
- Batch size: 2
- Learning rate: 2e-4
- Gradient accumulation: 4
- FP16 pro GPU

#### Krok 6: UloÅ¾enÃ­ modelu
- LokÃ¡lnÃ­ uloÅ¾enÃ­
- NahrÃ¡nÃ­ na Hugging Face Hub (volitelnÃ©)

### ğŸ¯ PodporovanÃ© modely
- **Llama 3 8B** (hlavnÃ­)
- **Mistral 7B** (alternativnÃ­)
- **LoRA** (Low-Rank Adaptation)

### ğŸ“Š VÃ½stup
- **Fine-tuned model** v `./babis-llama-finetuned/final`
- **LoRA adaptÃ©ry** pro efektivnÃ­ uloÅ¾enÃ­
- **Training metrics** a logy

---

## ğŸ“ˆ ÄŒÃST 3: Benchmarking

### ğŸ¯ CÃ­l
Srovnat model pÅ™ed a po fine-tuningu pomocÃ­ benchmarkingu.

### ğŸ“ Struktura
```
benchmarking/
â”œâ”€â”€ evaluation/             # Evaluace modelÅ¯
â”œâ”€â”€ tests/                  # TestovacÃ­ data
â”œâ”€â”€ reports/                # Reporty
â”œâ”€â”€ utils/                  # PomocnÃ© funkce
â””â”€â”€ run_benchmarking.py     # HlavnÃ­ skript
```

### ğŸ”§ Implementace

#### Krok 1: NaÄtenÃ­ modelÅ¯
- Base model (pÅ™ed fine-tuningem)
- Fine-tuned model (po fine-tuningem)

#### Krok 2: KvantitativnÃ­ metriky
- **Perplexity** - mÄ›Å™enÃ­ jazykovÃ©ho modelu
- **BLEU score** - kvalita pÅ™ekladu/generovÃ¡nÃ­
- **ROUGE score** - pÅ™ekryv s referenÄnÃ­mi texty
- **PrÅ¯mÄ›rnÃ¡ dÃ©lka odpovÄ›dÃ­**

#### Krok 3: KvalitativnÃ­ evaluace
- **StylovÃ¡ podobnost** - napodobenÃ­ "babÃ­Å¡ovÅ¡tiny"
- **TematickÃ¡ relevance** - odpovÃ­dÃ¡nÃ­ na otÃ¡zky
- **JazykovÃ© chyby** - zÃ¡mÄ›rnÃ© vs. skuteÄnÃ© chyby
- **Emotivnost** - charakteristickÃ© vÃ½razy

#### Krok 4: VÃ½konnostnÃ­ metriky
- **GeneraÄnÃ­ rychlost** - tokens za sekundu
- **PamÄ›Å¥ovÃ¡ nÃ¡roÄnost** - VRAM vyuÅ¾itÃ­
- **Latence** - doba odezvy

#### Krok 5: GenerovÃ¡nÃ­ reportu
- HTML report s vizualizacemi
- JSON data pro dalÅ¡Ã­ analÃ½zu
- Grafy a tabulky

### ğŸ“Š Metriky

#### KvantitativnÃ­:
- Perplexity (niÅ¾Å¡Ã­ = lepÅ¡Ã­)
- BLEU score (vyÅ¡Å¡Ã­ = lepÅ¡Ã­)
- ROUGE score (vyÅ¡Å¡Ã­ = lepÅ¡Ã­)

#### KvalitativnÃ­:
- StylovÃ¡ podobnost (0-1)
- TematickÃ¡ relevance (0-1)
- Emotivnost (0-1)

#### VÃ½konnostnÃ­:
- GeneraÄnÃ­ rychlost (resp/s)
- PamÄ›Å¥ovÃ¡ nÃ¡roÄnost (GB)
- Latence (sekundy)

### ğŸ“Š VÃ½stup
- **HTML report** s kompletnÃ­ analÃ½zou
- **JSON data** pro dalÅ¡Ã­ zpracovÃ¡nÃ­
- **Grafy** a vizualizace
- **TestovacÃ­ odpovÄ›di** pro porovnÃ¡nÃ­

---

## ğŸ“‹ KompletnÃ­ workflow

### 1ï¸âƒ£ PÅ™Ã­prava datasetu
```bash
cd dataset_preparation
python run_dataset_preparation.py --complete
```

### 2ï¸âƒ£ Fine-tuning modelu
```bash
cd fine_tuning
python run_finetune.py \
    --model_name "meta-llama/Meta-Llama-3-8B-Instruct" \
    --data_path "data/all.jsonl" \
    --output_dir "./babis-llama-finetuned" \
    --epochs 3 \
    --batch_size 2
```

### 3ï¸âƒ£ Benchmarking
```bash
cd benchmarking
python run_benchmarking.py \
    --base_model "meta-llama/Meta-Llama-3-8B-Instruct" \
    --finetuned_model_path "./babis-llama-finetuned/final"
```

---

## ğŸ› ï¸ Instalace a nastavenÃ­

### PoÅ¾adavky
```bash
# Python 3.8+
python --version

# GPU (doporuÄeno)
nvidia-smi

# ZÃ¡vislosti
pip install torch transformers peft datasets wandb evaluate nltk rouge-score matplotlib seaborn pandas
```

### NastavenÃ­ tokenÅ¯
```bash
# Hugging Face token
export HF_TOKEN="your_token_here"

# Weights & Biases token (volitelnÃ©)
export WANDB_API_KEY="your_wandb_token_here"
```

### Kontrola pÅ™edpokladÅ¯
```bash
python run_complete_workflow.py --check-only
```

---

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

### Dataset:
- âœ… 3,000 QA pÃ¡rÅ¯
- âœ… StrukturovanÃ½ formÃ¡t
- âœ… ModerovanÃ½ obsah

### Fine-tuned model:
- âœ… Styl Andreje BabiÅ¡e
- âœ… CharakteristickÃ© frÃ¡ze
- âœ… EmotivnÃ­ odpovÄ›di

### Benchmarking:
- âœ… KvantitativnÃ­ srovnÃ¡nÃ­
- âœ… KvalitativnÃ­ evaluace
- âœ… VÃ½konnostnÃ­ metriky

---

## ğŸ¯ SplnÄ›nÃ­ zadÃ¡nÃ­

âœ… **Metoda fine-tuningu** - Hugging Face + PEFT (LoRA)  
âœ… **SrovnÃ¡nÃ­ pÅ™ed/po** - KompletnÃ­ benchmarking  
âœ… **BodovÃ© ohodnocenÃ­** - KvantitativnÃ­ metriky  
âœ… **Forma odevzdÃ¡nÃ­** - Report s tabulkami a screenshoty  

---

## ğŸ“ VÃ½stupnÃ­ soubory

Po spuÅ¡tÄ›nÃ­ kompletnÃ­ho workflow budete mÃ­t:

```
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ all.jsonl                    # FinÃ¡lnÃ­ dataset
â”œâ”€â”€ babis-llama-finetuned/
â”‚   â””â”€â”€ final/                       # Fine-tuned model
â”œâ”€â”€ benchmarking/
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ benchmark_report.html    # HTML report
â”‚   â”‚   â”œâ”€â”€ benchmark_report.json    # JSON data
â”‚   â”‚   â””â”€â”€ *.png                    # Grafy
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ model_responses.json     # TestovacÃ­ odpovÄ›di
â”œâ”€â”€ workflow_completion_report.json  # ShrnutÃ­ workflow
â””â”€â”€ *.log                           # Logy
```

---

## ğŸš€ DalÅ¡Ã­ kroky

1. **SpusÅ¥te kompletnÃ­ workflow:**
   ```bash
   python run_complete_workflow.py --complete
   ```

2. **ProhlÃ©dnÄ›te si vÃ½sledky:**
   - HTML report: `benchmarking/reports/benchmark_report.html`
   - JSON data: `benchmarking/reports/benchmark_report.json`
   - TestovacÃ­ odpovÄ›di: `benchmarking/tests/model_responses.json`

3. **Odevzdejte vÃ½sledky:**
   - Screenshoty z HTML reportu
   - Tabulky s metrikami
   - PorovnÃ¡nÃ­ odpovÄ›dÃ­ pÅ™ed/po fine-tuningu

---

## ğŸ”§ Troubleshooting

### ProblÃ©my s GPU
```bash
# Kontrola GPU
nvidia-smi

# SnÃ­Å¾enÃ­ batch size
python fine_tuning/run_finetune.py --batch_size 1
```

### ProblÃ©my s pamÄ›tÃ­
```bash
# PouÅ¾itÃ­ 8-bit kvantizace
python fine_tuning/run_finetune.py --load_in_8bit

# Nebo 4-bit kvantizace
python fine_tuning/run_finetune.py --load_in_4bit
```

### ProblÃ©my s datasetem
```bash
# Kontrola datasetu
python dataset_preparation/run_dataset_preparation.py --step 1
```

---

## ğŸ“ PoznÃ¡mky

- **ÄŒasovÃ¡ nÃ¡roÄnost:** Fine-tuning mÅ¯Å¾e trvat nÄ›kolik hodin
- **HardwarovÃ© poÅ¾adavky:** DoporuÄeno GPU s minimÃ¡lnÄ› 16GB VRAM
- **Tokeny:** Pro nahrÃ¡nÃ­ na HF Hub je potÅ™eba HF_TOKEN
- **Monitoring:** W&B logging pro sledovÃ¡nÃ­ prÅ¯bÄ›hu trÃ©novÃ¡nÃ­

---

## ğŸ‰ Hotovo!

VÅ¡e je pÅ™ipraveno k pouÅ¾itÃ­! SpusÅ¥te kompletnÃ­ workflow a zÃ­skejte vÃ½sledky pro odevzdÃ¡nÃ­ Ãºkolu.

```bash
python run_complete_workflow.py --complete
``` 