# ğŸ¯ Fine-tuning Projekt: KompletnÃ­ Å™eÅ¡enÃ­

## ğŸ“‹ PÅ™ehled projektu

Tento projekt implementuje **kompletnÃ­ Å™eÅ¡enÃ­ fine-tuningu jazykovÃ©ho modelu** rozdÄ›lenÃ© na **3 hlavnÃ­ ÄÃ¡sti** podle zadÃ¡nÃ­ Ãºkolu:

1. **[ğŸ“Š PÅ™Ã­prava dat](#1-pÅ™Ã­prava-dat)** - VytvoÅ™enÃ­ trÃ©novacÃ­ch datasetÅ¯
2. **[ğŸ‹ï¸ Fine-tuning modelu](#2-fine-tuning)** - DoladÄ›nÃ­ jazykovÃ©ho modelu  
3. **[ğŸ“ˆ Benchmarking](#3-benchmarking)** - SrovnÃ¡nÃ­ pÅ™ed a po fine-tuningu

---

## ğŸ¯ CÃ­le Ãºkolu

### HlavnÃ­ cÃ­l
VytvoÅ™it fine-tuned jazykovÃ½ model, kterÃ½ napodobuje komunikaÄnÃ­ styl Andreje BabiÅ¡e, ÄeskÃ©ho politika znÃ¡mÃ©ho svÃ½m charakteristickÃ½m zpÅ¯sobem vyjadÅ™ovÃ¡nÃ­.

### KlÃ­ÄovÃ© poÅ¾adavky
- **Metoda fine-tuningu**: Implementace Hugging Face + PEFT (LoRA) pÅ™Ã­stupu
- **SrovnÃ¡nÃ­ pÅ™ed/po**: KompletnÃ­ benchmarking analÃ½za
- **KvantitativnÃ­ evaluace**: BodovÃ½ systÃ©m hodnocenÃ­
- **Forma odevzdÃ¡nÃ­**: Report s tabulkami a screenshoty

### KritÃ©ria ÃºspÄ›chu
- Model generuje odpovÄ›di v charakteristickÃ©m BabiÅ¡ovÄ› stylu
- MÄ›Å™itelnÃ© zlepÅ¡enÃ­ v napodobovÃ¡nÃ­ stylu
- KomplexnÃ­ metriky vÃ½konu
- ReprodukovatelnÃ© vÃ½sledky

---

## ğŸ—ï¸ Architektura Å™eÅ¡enÃ­

### TÅ™Ã­dÃ­lnÃ¡ implementace

#### [1. PÅ™Ã­prava dat](#1-pÅ™Ã­prava-dat)
- **UmÃ­stÄ›nÃ­**: `1_data_preparation/`
- **README**: [PrÅ¯vodce pÅ™Ã­pravou dat](1_data_preparation/README.md)
- **ÃšÄel**: GenerovÃ¡nÃ­ kvalitnÃ­ch trÃ©novacÃ­ch dat v BabiÅ¡ovÄ› stylu
- **VÃ½stup**: 1,500 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu

#### [2. Fine-tuning](#2-fine-tuning)
- **UmÃ­stÄ›nÃ­**: `2_finetunning/`
- **README**: [PrÅ¯vodce fine-tuningem](2_finetunning/README.md)
- **ÃšÄel**: Fine-tuning jazykovÃ©ho modelu pomocÃ­ LoRA techniky
- **VÃ½stup**: Fine-tuned model s adaptacÃ­ stylu

#### [3. Benchmarking](#3-benchmarking)
- **UmÃ­stÄ›nÃ­**: `3_benchmarking/`
- **README**: [PrÅ¯vodce benchmarkingem](3_benchmarking/README.md)
- **ÃšÄel**: Evaluace vÃ½konu modelu pÅ™ed a po fine-tuningu
- **VÃ½stup**: KomplexnÃ­ srovnÃ¡vacÃ­ report

---

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

### PÅ™Ã­prava dat
- âœ… 1,500 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu
- âœ… AutentickÃ½ BabiÅ¡Å¯v komunikaÄnÃ­ styl
- âœ… ModerovanÃ½ obsah datasetu
- âœ… VÃ­ce stylovÃ½ch variacÃ­

### Fine-tuning
- âœ… LoRA-adaptovanÃ½ model
- âœ… StylovÄ› specifickÃ© odpovÄ›di
- âœ… EfektivnÃ­ vyuÅ¾itÃ­ parametrÅ¯
- âœ… ReprodukovatelnÃ© trÃ©novÃ¡nÃ­

### Benchmarking
- âœ… KvantitativnÃ­ metriky vÃ½konu
- âœ… KvalitativnÃ­ evaluace stylu
- âœ… SrovnÃ¡nÃ­ pÅ™ed/po
- âœ… KomplexnÃ­ analytickÃ½ report

---

## ğŸ“ Struktura projektu

```
talklike.llm/
â”œâ”€â”€ 1_data_preparation/          # ğŸ“Š PÅ™Ã­prava dat
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce pÅ™Ã­pravou dat
â”‚   â”œâ”€â”€ QUICKSTART.md           # RychlÃ½ start
â”‚   â””â”€â”€ run_data_preparation.py # HlavnÃ­ skript
â”œâ”€â”€ 2_finetunning/              # ğŸ‹ï¸ Fine-tuning
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce fine-tuningem
â”‚   â”œâ”€â”€ finetune_babis.py       # HlavnÃ­ skript
â”‚   â””â”€â”€ run_finetune.sh         # SpouÅ¡tÄ›cÃ­ skript
â”œâ”€â”€ 3_benchmarking/             # ğŸ“ˆ Benchmarking
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce benchmarkingem
â”‚   â”œâ”€â”€ run_benchmark.py        # HlavnÃ­ skript
â”‚   â””â”€â”€ results/                # VÃ½sledky
â”œâ”€â”€ data/                       # ğŸ“Š Datasety
â”‚   â”œâ”€â”€ all.jsonl              # FinÃ¡lnÃ­ dataset
â”‚   â””â”€â”€ final/                 # QA pÃ¡ry
â””â”€â”€ lib/                        # ğŸ“š Knihovny
    â”œâ”€â”€ babis_dataset_generator.py
    â””â”€â”€ llm_cost_calculator.py
```

---

## ğŸš€ RychlÃ½ start

### 1. PÅ™Ã­prava dat
```bash
cd 1_data_preparation
pip install -r requirements_datapreparation.txt
python run_data_preparation.py
```

### 2. Fine-tuning
```bash
cd 2_finetunning
pip install -r requirements_finetunning.txt
./run_finetune.sh
```

### 3. Benchmarking
```bash
cd 3_benchmarking
pip install -r requirements_benchmarking.txt
python run_benchmark.py
```

---

## ğŸ“š Dokumentace

- **[ğŸ“Š PÅ™Ã­prava dat](1_data_preparation/README.md)** - KompletnÃ­ prÅ¯vodce pÅ™Ã­pravou datasetu
- **[ğŸ‹ï¸ Fine-tuning](2_finetunning/README.md)** - DetailnÃ­ nÃ¡vod na fine-tuning
- **[ğŸ“ˆ Benchmarking](3_benchmarking/README.md)** - Evaluace a srovnÃ¡nÃ­ modelÅ¯
- **[ğŸš€ RychlÃ½ start](1_data_preparation/QUICKSTART.md)** - RychlÃ© spuÅ¡tÄ›nÃ­ pÅ™Ã­pravy dat
- **[âš¡ Fine-tuning start](2_finetunning/RUNPOD_SETUP.md)** - NastavenÃ­ pro RunPod.io

---

## ğŸ¯ VÃ½sledky

Projekt generuje kompletnÃ­ fine-tuned model s nÃ¡sledujÃ­cÃ­mi vÃ½stupy:

1. **Dataset**: 1,500 QA pÃ¡rÅ¯ v BabiÅ¡ovÄ› stylu
2. **Model**: Fine-tuned Meta-Llama-3-8B-Instruct s LoRA
3. **Report**: KomplexnÃ­ benchmarking analÃ½za s tabulkami a grafy
4. **Dokumentace**: KompletnÃ­ prÅ¯vodce pro reprodukci vÃ½sledkÅ¯

VÅ¡echny vÃ½sledky jsou uloÅ¾eny v pÅ™Ã­sluÅ¡nÃ½ch sloÅ¾kÃ¡ch a jsou pÅ™ipraveny pro odevzdÃ¡nÃ­ Ãºkolu.

