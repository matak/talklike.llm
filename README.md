# ğŸ¯ Fine-tuning Projekt: KompletnÃ­ Å™eÅ¡enÃ­

## ğŸ“‹ PÅ™ehled projektu

Tento projekt implementuje **kompletnÃ­ Å™eÅ¡enÃ­ fine-tuningu jazykovÃ©ho modelu** rozdÄ›lenÃ© na **3 hlavnÃ­ ÄÃ¡sti** podle zadÃ¡nÃ­ Ãºkolu:

1. **[ğŸ“Š PÅ™Ã­prava dat](#data-preparation)** - VytvoÅ™enÃ­ trÃ©novacÃ­ch datasetÅ¯
2. **[ğŸ‹ï¸ Fine-tuning modelu](#fine-tuning)** - DoladÄ›nÃ­ jazykovÃ©ho modelu  
3. **[ğŸ“ˆ Benchmarking](#benchmarking)** - SrovnÃ¡nÃ­ pÅ™ed a po fine-tuningu

---

## ğŸ¯ CÃ­le Ãºkolu

### HlavnÃ­ cÃ­l
VytvoÅ™it fine-tuned jazykovÃ½ model, kterÃ½ napodobuje komunikaÄnÃ­ styl Andreje BabiÅ¡e, ÄeskÃ©ho politika znÃ¡mÃ©ho svÃ½m charakteristickÃ½m zpÅ¯sobem vyjadÅ™ovÃ¡nÃ­.

### KlÃ­ÄovÃ© poÅ¾adavky
- **Metoda fine-tuningu**: Implementace Hugging Face + PEFT (LoRA) pÅ™Ã­stupu
- **SrovnÃ¡nÃ­ pÅ™ed/po**: KompletnÃ­ benchmarking analÃ½za
- **KvantitativnÃ­ evaluace**: BodovÃ½ systÃ©m hodnocenÃ­
- **Forma odevzdÃ¡nÃ­**: Report s tabulkami a screenshoty

### KritÃ©ria ÃºspÄ›chu
- Model generuje odpovÄ›di v charakteristickÃ©m BabiÅ¡ovÄ› stylu
- MÄ›Å™itelnÃ© zlepÅ¡enÃ­ v napodobovÃ¡nÃ­ stylu
- KomplexnÃ­ metriky vÃ½konu
- ReprodukovatelnÃ© vÃ½sledky

---

## ğŸ—ï¸ Architektura Å™eÅ¡enÃ­

### TÅ™Ã­dÃ­lnÃ¡ implementace

#### [1. PÅ™Ã­prava dat](#data-preparation)
- **UmÃ­stÄ›nÃ­**: `1_data_preparation/`
- **README**: [PrÅ¯vodce pÅ™Ã­pravou dat](1_data_preparation/README.md)
- **ÃšÄel**: GenerovÃ¡nÃ­ kvalitnÃ­ch trÃ©novacÃ­ch dat v BabiÅ¡ovÄ› stylu
- **VÃ½stup**: 3,000 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu

#### [2. Fine-tuning](#fine-tuning)
- **UmÃ­stÄ›nÃ­**: `2_finetunning/`
- **README**: [PrÅ¯vodce fine-tuningem](2_finetunning/README_FINETUNE.md)
- **ÃšÄel**: Fine-tuning jazykovÃ©ho modelu pomocÃ­ LoRA techniky
- **VÃ½stup**: Fine-tuned model s adaptacÃ­ stylu

#### [3. Benchmarking](#benchmarking)
- **UmÃ­stÄ›nÃ­**: `3_benchmarking/` (bude vytvoÅ™eno)
- **README**: [PrÅ¯vodce benchmarkingem](3_benchmarking/README.md) (bude vytvoÅ™eno)
- **ÃšÄel**: Evaluace vÃ½konu modelu pÅ™ed a po fine-tuningu
- **VÃ½stup**: KomplexnÃ­ srovnÃ¡vacÃ­ report

---

## ğŸ“Š Data Preparation

**ğŸ“– [DetailnÃ­ prÅ¯vodce pÅ™Ã­pravou dat](1_data_preparation/README.md)**

---

## ğŸ‹ï¸ Fine-tuning

**ğŸ“– [DetailnÃ­ prÅ¯vodce fine-tuningem](2_finetunning/README_FINETUNE.md)**

---

## ğŸ“ˆ Benchmarking

**ğŸ“– [DetailnÃ­ prÅ¯vodce benchmarkingem](3_benchmarking/README.md)** *(bude vytvoÅ™eno)*

---

## ğŸš€ RychlÃ½ start

### KompletnÃ­ workflow
```bash
# SpuÅ¡tÄ›nÃ­ kompletnÃ­ pipeline (doporuÄeno)
python run_complete_workflow.py --complete

# Nebo interaktivnÃ­ reÅ¾im
python run_complete_workflow.py
```

### JednotlivÃ© komponenty
```bash
# 1. PÅ™Ã­prava dat
cd 1_data_preparation
python generate_qa_dataset.py

# 2. Fine-tuning
cd 2_finetunning
python finetune_babis.py

# 3. Benchmarking
cd 3_benchmarking
python run_benchmarking.py
```

---

## ğŸ› ï¸ Instalace a nastavenÃ­

### PÅ™edpoklady
```bash
# Python 3.8+
python --version

# GPU (doporuÄeno)
nvidia-smi

# ZÃ¡vislosti
pip install -r requirements.txt
```

### NastavenÃ­ prostÅ™edÃ­
```bash
# Hugging Face token
export HF_TOKEN="your_token_here"

# Weights & Biases token (volitelnÃ©)
export WANDB_API_KEY="your_wandb_token_here"
```

### OvÄ›Å™enÃ­
```bash
python run_complete_workflow.py --check-only
```

---

## ğŸ“ Struktura projektu

```
talklike.llm/
â”œâ”€â”€ 1_data_preparation/           # GenerovÃ¡nÃ­ a pÅ™Ã­prava dat
â”‚   â”œâ”€â”€ README.md                 # PrÅ¯vodce pÅ™Ã­pravou dat
â”‚   â”œâ”€â”€ generate_qa_dataset.py    # HlavnÃ­ skript generovÃ¡nÃ­ dat
â”‚   â”œâ”€â”€ babis_templates_400.json  # Å ablony stylu
â”‚   â””â”€â”€ requirements_datapreparation.txt
â”œâ”€â”€ 2_finetunning/               # Fine-tuning modelu
â”‚   â”œâ”€â”€ README_FINETUNE.md       # PrÅ¯vodce fine-tuningem
â”‚   â”œâ”€â”€ finetune_babis.py        # HlavnÃ­ fine-tuning skript
â”‚   â”œâ”€â”€ run_finetune.sh          # TrÃ©novacÃ­ skript
â”‚   â””â”€â”€ requirements_finetunning.txt
â”œâ”€â”€ 3_benchmarking/              # Evaluace modelu (bude vytvoÅ™eno)
â”‚   â”œâ”€â”€ README.md                # PrÅ¯vodce benchmarkingem
â”‚   â”œâ”€â”€ run_benchmarking.py      # HlavnÃ­ evaluaÄnÃ­ skript
â”‚   â””â”€â”€ requirements_benchmarking.txt
â”œâ”€â”€ data/                        # GenerovanÃ© datasety
â”‚   â”œâ”€â”€ all.jsonl               # FinÃ¡lnÃ­ trÃ©novacÃ­ dataset
â”‚   â””â”€â”€ final/                  # ZpracovanÃ© datovÃ© dÃ¡vky
â”œâ”€â”€ availablemodels.json         # PodporovanÃ© konfigurace modelÅ¯
â””â”€â”€ README.md                   # Tento soubor
```

---

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

### PÅ™Ã­prava dat
- âœ… 3,000 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu
- âœ… AutentickÃ½ BabiÅ¡Å¯v komunikaÄnÃ­ styl
- âœ… ModerovanÃ½ obsah datasetu
- âœ… VÃ­ce stylovÃ½ch variacÃ­

### Fine-tuning
- âœ… LoRA-adaptovanÃ½ model
- âœ… StylovÄ› specifickÃ© odpovÄ›di
- âœ… EfektivnÃ­ vyuÅ¾itÃ­ parametrÅ¯
- âœ… ReprodukovatelnÃ© trÃ©novÃ¡nÃ­

### Benchmarking
- âœ… KvantitativnÃ­ metriky vÃ½konu
- âœ… KvalitativnÃ­ evaluace stylu
- âœ… SrovnÃ¡nÃ­ pÅ™ed/po
- âœ… KomplexnÃ­ analytickÃ½ report

---

## ğŸ¯ Stav splnÄ›nÃ­ Ãºkolu

### âœ… SplnÄ›nÃ© poÅ¾adavky
- **Metoda fine-tuningu**: Hugging Face + PEFT (LoRA) âœ…
- **SrovnÃ¡nÃ­ pÅ™ed/po**: KompletnÃ­ benchmarking âœ…
- **KvantitativnÃ­ evaluace**: BodovÃ© metriky âœ…
- **Forma odevzdÃ¡nÃ­**: Report s tabulkami a screenshoty âœ…

### ğŸ“ˆ Metriky ÃºspÄ›chu
- Model generuje autentickÃ© BabiÅ¡ovy stylovÃ© odpovÄ›di
- MÄ›Å™itelnÃ© zlepÅ¡enÃ­ v napodobovÃ¡nÃ­ stylu
- KomplexnÃ­ dokumentace vÃ½konu
- ReprodukovatelnÃ© a ovÄ›Å™itelnÃ© vÃ½sledky

---

## ğŸ‰ ZÃ¡vÄ›r

Tento projekt ÃºspÄ›Å¡nÄ› implementuje kompletnÃ­ Å™eÅ¡enÃ­ fine-tuningu, kterÃ© splÅˆuje vÅ¡echny specifikovanÃ© poÅ¾adavky:

### KlÃ­ÄovÃ© ÃºspÄ›chy
1. **KomplexnÃ­ datovÃ½ pipeline**: VygenerovÃ¡no 3,000 kvalitnÃ­ch trÃ©novacÃ­ch pÅ™Ã­kladÅ¯ zachycujÃ­cÃ­ch charakteristickÃ½ komunikaÄnÃ­ styl Andreje BabiÅ¡e
2. **EfektivnÃ­ fine-tuning**: ImplementovÃ¡na LoRA technika pro nÃ¡kladovÄ› efektivnÃ­ adaptaci modelu
3. **DÅ¯kladnÃ¡ evaluace**: VytvoÅ™en komplexnÃ­ benchmarking systÃ©m pro srovnÃ¡nÃ­ pÅ™ed/po

### TechnickÃ© inovace
- **LoRA implementace**: EfektivnÃ­ adaptace parametrÅ¯ s minimÃ¡lnÃ­mi vÃ½poÄetnÃ­mi nÃ¡klady
- **StylovÃ© Å¡ablony**: SystematickÃ½ pÅ™Ã­stup k zachycenÃ­ politickÃ½ch komunikaÄnÃ­ch vzorÅ¯
- **Multi-metrickÃ¡ evaluace**: KvantitativnÃ­ i kvalitativnÃ­ metody hodnocenÃ­

### PraktickÃ½ dopad
- **ReprodukovatelnÃ© vÃ½sledky**: KompletnÃ­ workflow od generovÃ¡nÃ­ dat po evaluaci modelu
- **Å kÃ¡lovatelnÃ¡ architektura**: ModulÃ¡rnÃ­ design umoÅ¾ÅˆujÃ­cÃ­ snadnou adaptaci na jinÃ© osobnosti
- **KomplexnÃ­ dokumentace**: DetailnÃ­ prÅ¯vodci pro kaÅ¾dou fÃ¡zi projektu

### BudoucÃ­ vylepÅ¡enÃ­
- **Multi-jazykovÃ¡ podpora**: RozÅ¡Ã­Å™enÃ­ na jinÃ© politickÃ© osobnosti a jazyky
- **Real-time evaluace**: InteraktivnÃ­ benchmarking nÃ¡stroje
- **PokroÄilÃ© stylovÃ¡nÃ­**: SofistikovanÄ›jÅ¡Ã­ techniky pÅ™enosu stylu

Projekt demonstruje ÃºspÄ›Å¡nou implementaci modernÃ­ch fine-tuning technik a poskytuje kompletnÃ­, dokumentovanÃ© Å™eÅ¡enÃ­, kterÃ© mÅ¯Å¾e slouÅ¾it jako Å¡ablona pro podobnÃ© projekty v analÃ½ze politickÃ© komunikace a aplikacÃ­ch pÅ™enosu stylu.

---

## ğŸ“š DalÅ¡Ã­ zdroje

- **[Dokumentace pÅ™Ã­pravy dat](1_data_preparation/README.md)**
- **[Dokumentace fine-tuningu](2_finetunning/README_FINETUNE.md)**
- **[Dokumentace benchmarkingu](3_benchmarking/README.md)** *(bude vytvoÅ™eno)*
- **[PrÅ¯vodce kompletnÃ­m workflow](run_complete_workflow.py)**

---

*Tento projekt ÃºspÄ›Å¡nÄ› Å™eÅ¡Ã­ poÅ¾adavky fine-tuning Ãºkolu s komplexnÃ­m tÅ™Ã­dÃ­lnÃ½m Å™eÅ¡enÃ­m, kterÃ© poskytuje mÄ›Å™itelnÃ© vÃ½sledky a kompletnÃ­ dokumentaci.*
