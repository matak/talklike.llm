# ğŸ¯ Fine-tuning Projekt: KompletnÃ­ Å™eÅ¡enÃ­

## ğŸ“‹ PÅ™ehled projektu

Tento projekt implementuje **kompletnÃ­ Å™eÅ¡enÃ­ fine-tuningu jazykovÃ©ho modelu** rozdÄ›lenÃ© na **3 hlavnÃ­ ÄÃ¡sti** podle zadÃ¡nÃ­ Ãºkolu:

1. **[ğŸ“Š PÅ™Ã­prava dat](#1-pÅ™Ã­prava-dat)** - VytvoÅ™enÃ­ trÃ©novacÃ­ch datasetÅ¯
2. **[ğŸ‹ï¸ Fine-tuning modelu](#2-fine-tuning)** - DoladÄ›nÃ­ jazykovÃ©ho modelu  
3. **[ğŸ“ˆ Benchmarking](#3-benchmarking)** - SrovnÃ¡nÃ­ pÅ™ed a po fine-tuningu

---

## ğŸ¤– NahranÃ© modely

### KompletnÃ­ fine-tuned model
- **Model**: [mcmatak/mistral-babis-model](https://huggingface.co/mcmatak/mistral-babis-model)
- **Typ**: KompletnÃ­ Mistral-7B-Instruct-v0.3 model fine-tuned na BabiÅ¡Å¯v styl
- **Velikost**: ~14GB (34 shardÅ¯)
- **PouÅ¾itÃ­**: PÅ™Ã­mÃ© pouÅ¾itÃ­ bez dalÅ¡Ã­ch krokÅ¯

### LoRA adapter
- **Model**: [mcmatak/mistral-babis-adapter](https://huggingface.co/mcmatak/mistral-babis-adapter)
- **Typ**: LoRA adapter pro Mistral-7B-Instruct-v0.3
- **Velikost**: ~84MB
- **PouÅ¾itÃ­**: VyÅ¾aduje base model + adapter

### PouÅ¾itÃ­ modelÅ¯

#### KompletnÃ­ model
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained('mcmatak/mistral-babis-model')
tokenizer = AutoTokenizer.from_pretrained('mcmatak/mistral-babis-model')
```

#### LoRA adapter
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained('mistralai/Mistral-7B-Instruct-v0.3')
model = PeftModel.from_pretrained(base_model, 'mcmatak/mistral-babis-adapter')
tokenizer = AutoTokenizer.from_pretrained('mcmatak/mistral-babis-adapter')
```

---

## ğŸ¯ CÃ­le Ãºkolu

### HlavnÃ­ cÃ­l
VytvoÅ™it fine-tuned jazykovÃ½ model, kterÃ½ napodobuje komunikaÄnÃ­ styl Andreje BabiÅ¡e, ÄeskÃ©ho politika znÃ¡mÃ©ho svÃ½m charakteristickÃ½m zpÅ¯sobem vyjadÅ™ovÃ¡nÃ­.

### KlÃ­ÄovÃ© poÅ¾adavky
- **Metoda fine-tuningu**: Implementace Hugging Face + PEFT (LoRA) pÅ™Ã­stupu
- **SrovnÃ¡nÃ­ pÅ™ed/po**: KompletnÃ­ benchmarking analÃ½za
- **KvantitativnÃ­ evaluace**: BodovÃ½ systÃ©m hodnocenÃ­
- **Forma odevzdÃ¡nÃ­**: Report s tabulkami a screenshoty

### KritÃ©ria ÃºspÄ›chu
- Model generuje odpovÄ›di v charakteristickÃ©m BabiÅ¡ovÄ› stylu
- MÄ›Å™itelnÃ© zlepÅ¡enÃ­ v napodobovÃ¡nÃ­ stylu
- KomplexnÃ­ metriky vÃ½konu
- ReprodukovatelnÃ© vÃ½sledky

---

## ğŸ—ï¸ Architektura Å™eÅ¡enÃ­

### TÅ™Ã­dÃ­lnÃ¡ implementace

#### [1. PÅ™Ã­prava dat](#1-pÅ™Ã­prava-dat)
- **UmÃ­stÄ›nÃ­**: `1_data_preparation/`
- **README**: [PrÅ¯vodce pÅ™Ã­pravou dat](1_data_preparation/README.md)
- **ÃšÄel**: GenerovÃ¡nÃ­ kvalitnÃ­ch trÃ©novacÃ­ch dat v BabiÅ¡ovÄ› stylu
- **VÃ½stup**: 1,500 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu

#### [2. Fine-tuning](#2-fine-tuning)
- **UmÃ­stÄ›nÃ­**: `2_finetunning/`
- **README**: [PrÅ¯vodce fine-tuningem](2_finetunning/README.md)
- **ÃšÄel**: Fine-tuning jazykovÃ©ho modelu pomocÃ­ LoRA techniky
- **VÃ½stup**: Fine-tuned model s adaptacÃ­ stylu

#### [3. Benchmarking](#3-benchmarking)
- **UmÃ­stÄ›nÃ­**: `3_benchmarking/`
- **README**: [PrÅ¯vodce benchmarkingem](3_benchmarking/README.md)
- **ÃšÄel**: Evaluace vÃ½konu modelu pÅ™ed a po fine-tuningu
- **VÃ½stup**: KomplexnÃ­ srovnÃ¡vacÃ­ report

---

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

### PÅ™Ã­prava dat
- âœ… 1,500 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu
- âœ… AutentickÃ½ BabiÅ¡Å¯v komunikaÄnÃ­ styl
- âœ… ModerovanÃ½ obsah datasetu
- âœ… VÃ­ce stylovÃ½ch variacÃ­

### Fine-tuning
- âœ… LoRA-adaptovanÃ½ model
- âœ… StylovÄ› specifickÃ© odpovÄ›di
- âœ… EfektivnÃ­ vyuÅ¾itÃ­ parametrÅ¯
- âœ… ReprodukovatelnÃ© trÃ©novÃ¡nÃ­

### Benchmarking
- âœ… KvantitativnÃ­ metriky vÃ½konu (zlepÅ¡enÃ­ z 1.17 na 4.58/10)
- âœ… KvalitativnÃ­ evaluace stylu (15 testovacÃ­ch otÃ¡zek)
- âœ… SrovnÃ¡nÃ­ pÅ™ed/po s detailnÃ­mi tabulkami
- âœ… KomplexnÃ­ analytickÃ½ report s vizualizacemi
- âœ… 4 typy grafÅ¯ pro rÅ¯znÃ© aspekty evaluace
- âœ… StrukturovanÃ¡ data pro dalÅ¡Ã­ analÃ½zu

---

## ğŸ“ Struktura projektu

```
talklike.llm/
â”œâ”€â”€ 1_data_preparation/          # ğŸ“Š PÅ™Ã­prava dat
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce pÅ™Ã­pravou dat
â”‚   â”œâ”€â”€ QUICKSTART.md           # RychlÃ½ start
â”‚   â””â”€â”€ run_data_preparation.py # HlavnÃ­ skript
â”œâ”€â”€ 2_finetunning/              # ğŸ‹ï¸ Fine-tuning
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce fine-tuningem
â”‚   â”œâ”€â”€ finetune.py             # HlavnÃ­ skript
â”‚   â””â”€â”€ run_mistral_finetune.sh # SpouÅ¡tÄ›cÃ­ skript
â”œâ”€â”€ 3_benchmarking/             # ğŸ“ˆ Benchmarking
â”‚   â”œâ”€â”€ README.md               # PrÅ¯vodce benchmarkingem
â”‚   â”œâ”€â”€ run_benchmark.py        # HlavnÃ­ skript
â”‚   â””â”€â”€ results/                # VÃ½sledky
â”‚       â”œâ”€â”€ reports/            # Markdown reporty
â”‚       â”œâ”€â”€ visualizations/     # Grafy a vizualizace
â”‚       â”œâ”€â”€ comparison/         # Data srovnÃ¡nÃ­
â”‚       â””â”€â”€ benchmark_dataset.json # TestovacÃ­ otÃ¡zky
â”œâ”€â”€ data/                       # ğŸ“Š Datasety
â”‚   â”œâ”€â”€ all.jsonl              # FinÃ¡lnÃ­ dataset
â”‚   â””â”€â”€ final/                 # QA pÃ¡ry
â””â”€â”€ lib/                        # ğŸ“š Knihovny
    â”œâ”€â”€ babis_dataset_generator.py
    â””â”€â”€ llm_cost_calculator.py
```

---

## ğŸ“ˆ Benchmarking vÃ½sledky

### ğŸ“‹ KompletnÃ­ report
- **[Benchmark Summary Report](3_benchmarking/results/reports/benchmark_summary.md)** - DetailnÃ­ srovnÃ¡nÃ­ modelu pÅ™ed a po fine-tuningu s tabulkami vÅ¡ech otÃ¡zek

### ğŸ“Š Vizualizace vÃ½sledkÅ¯

#### SrovnÃ¡nÃ­ skÃ³re
- **[SrovnÃ¡nÃ­ stylovÃ©ho skÃ³re](3_benchmarking/results/visualizations/score_comparison.png)** - Graf srovnÃ¡nÃ­ prÅ¯mÄ›rnÃ©ho skÃ³re pÅ™ed a po fine-tuningu

#### ZlepÅ¡enÃ­ jednotlivÃ½ch otÃ¡zek
- **[ZlepÅ¡enÃ­ stylovÃ©ho skÃ³re](3_benchmarking/results/visualizations/question_improvements.png)** - Graf zlepÅ¡enÃ­ pro kaÅ¾dou z 15 testovacÃ­ch otÃ¡zek

#### Distribuce znÃ¡mek
- **[Distribuce znÃ¡mek](3_benchmarking/results/visualizations/grade_distribution.png)** - Graf distribuce znÃ¡mek (A-F) pÅ™ed a po fine-tuningu

#### Kategorie stylu
- **[SrovnÃ¡nÃ­ kategoriÃ­ stylu](3_benchmarking/results/visualizations/category_comparison.png)** - Graf srovnÃ¡nÃ­ kategoriÃ­: BabiÅ¡ovy frÃ¡ze, slovenskÃ© odchylky, emotivnÃ­ tÃ³n, prvnÃ­ osoba

### ğŸ“„ DetailnÃ­ data
- **[Model Comparison Data](3_benchmarking/results/comparison/model_comparison.json)** - StrukturovanÃ¡ data srovnÃ¡nÃ­ modelÅ¯
- **[Style Evaluation Data](3_benchmarking/results/comparison/style_evaluation.json)** - DetailnÃ­ evaluace stylu pro kaÅ¾dou odpovÄ›Ä
- **[Benchmark Dataset](3_benchmarking/results/benchmark_dataset.json)** - TestovacÃ­ otÃ¡zky pouÅ¾itÃ© pro benchmarking

### ğŸ¯ KlÃ­ÄovÃ© vÃ½sledky
- **PrÅ¯mÄ›rnÃ© skÃ³re pÅ™ed fine-tuningem**: 1.17/10
- **PrÅ¯mÄ›rnÃ© skÃ³re po fine-tuningem**: 4.58/10
- **CelkovÃ© zlepÅ¡enÃ­**: +3.41 bodÅ¯
- **NejlepÅ¡Ã­ odpovÄ›Ä**: 8.5/10
- **NejhorÅ¡Ã­ odpovÄ›Ä**: 1.17/10

### ğŸ“Š Metriky zlepÅ¡enÃ­
- **BabiÅ¡ovy frÃ¡ze**: VÃ½raznÃ© zlepÅ¡enÃ­ v pouÅ¾Ã­vÃ¡nÃ­ charakteristickÃ½ch frÃ¡zÃ­
- **SlovenskÃ© odchylky**: SprÃ¡vnÃ© pouÅ¾itÃ­ slovenskÃ½ch odchylek
- **EmotivnÃ­ tÃ³n**: AutentickÃ½ emotivnÃ­ tÃ³n odpovÄ›dÃ­
- **PrvnÃ­ osoba**: KonzistentnÃ­ pouÅ¾itÃ­ prvnÃ­ osoby

---

## ğŸš€ RychlÃ½ start

### 1. PÅ™Ã­prava dat
```bash
# Z rootu projektu
python 1_data_preparation/run_data_preparation.py
```

### 2. Fine-tuning
```bash
# Z rootu projektu
./2_finetunning/run_mistral_finetune.sh
```

### 3. Benchmarking
```bash
# Z rootu projektu
python 3_benchmarking/run_benchmark.py
```

### AlternativnÃ­ spouÅ¡tÄ›nÃ­ (z adresÃ¡Å™Å¯)
```bash
# PÅ™Ã­prava dat
cd 1_data_preparation
pip install -r requirements_datapreparation.txt
python run_data_preparation.py

# Fine-tuning
cd 2_finetunning
pip install -r requirements_finetunning.txt
./run_mistral_finetune.sh

# Benchmarking
cd 3_benchmarking
pip install -r requirements_benchmarking.txt
python run_benchmark.py
```
