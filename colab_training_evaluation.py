# Evaluace modelu
print("ğŸ“Š SpouÅ¡tÃ­m evaluaci...")

eval_results = trainer.evaluate()

print("\nğŸ“ˆ VÃ½sledky evaluace:")
for key, value in eval_results.items():
    print(f"{key}: {value:.4f}")

# UloÅ¾enÃ­ metrik
trainer.log_metrics("eval", eval_results)
trainer.save_metrics("eval", eval_results)