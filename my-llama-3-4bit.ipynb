{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFqGFgQEWDBp"
      },
      "source": [
        "# Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA-rA2TMWDBq",
        "outputId": "046df9fb-7110-4e6d-920f-f17827e3d63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.6.15)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.7.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.6.15)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.7.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\n",
            "Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.52.4)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (0.21.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.6.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n",
        "%pip install transformers\n",
        "%pip install bitsandbytes\n",
        "%pip install accelerate\n",
        "%pip install peft\n",
        "%pip install datasets\n",
        "%pip install evaluate\n",
        "%pip install trl\n",
        "%pip install matplotlib\n",
        "%pip install tensorboard\n",
        "%pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jLjz_pBHcKvY",
        "outputId": "31ae32d2-e9fb-499c-8ab7-8b65ff9d3686"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                               Version\n",
            "------------------------------------- -------------------\n",
            "absl-py                               1.4.0\n",
            "accelerate                            1.7.0\n",
            "aiofiles                              24.1.0\n",
            "aiohappyeyeballs                      2.6.1\n",
            "aiohttp                               3.11.15\n",
            "aiosignal                             1.3.2\n",
            "alabaster                             1.0.0\n",
            "albucore                              0.0.24\n",
            "albumentations                        2.0.8\n",
            "ale-py                                0.11.1\n",
            "altair                                5.5.0\n",
            "annotated-types                       0.7.0\n",
            "antlr4-python3-runtime                4.9.3\n",
            "anyio                                 4.9.0\n",
            "argon2-cffi                           25.1.0\n",
            "argon2-cffi-bindings                  21.2.0\n",
            "array_record                          0.7.2\n",
            "arviz                                 0.21.0\n",
            "astropy                               7.1.0\n",
            "astropy-iers-data                     0.2025.6.16.0.38.47\n",
            "astunparse                            1.6.3\n",
            "atpublic                              5.1\n",
            "attrs                                 25.3.0\n",
            "audioread                             3.0.1\n",
            "autograd                              1.8.0\n",
            "babel                                 2.17.0\n",
            "backcall                              0.2.0\n",
            "backports.tarfile                     1.2.0\n",
            "beautifulsoup4                        4.13.4\n",
            "betterproto                           2.0.0b6\n",
            "bigframes                             2.6.0\n",
            "bigquery-magics                       0.9.0\n",
            "bitsandbytes                          0.46.0\n",
            "bleach                                6.2.0\n",
            "blinker                               1.9.0\n",
            "blis                                  1.3.0\n",
            "blobfile                              3.0.0\n",
            "blosc2                                3.4.0\n",
            "bokeh                                 3.7.3\n",
            "Bottleneck                            1.4.2\n",
            "bqplot                                0.12.45\n",
            "branca                                0.8.1\n",
            "build                                 1.2.2.post1\n",
            "CacheControl                          0.14.3\n",
            "cachetools                            5.5.2\n",
            "catalogue                             2.0.10\n",
            "certifi                               2025.6.15\n",
            "cffi                                  1.17.1\n",
            "chardet                               5.2.0\n",
            "charset-normalizer                    3.4.2\n",
            "chex                                  0.1.89\n",
            "clarabel                              0.11.1\n",
            "click                                 8.2.1\n",
            "cloudpathlib                          0.21.1\n",
            "cloudpickle                           3.1.1\n",
            "cmake                                 3.31.6\n",
            "cmdstanpy                             1.2.5\n",
            "colorcet                              3.1.0\n",
            "colorlover                            0.3.0\n",
            "colour                                0.1.5\n",
            "community                             1.0.0b1\n",
            "confection                            0.1.5\n",
            "cons                                  0.4.6\n",
            "contourpy                             1.3.2\n",
            "cramjam                               2.10.0\n",
            "cryptography                          43.0.3\n",
            "cuda-python                           12.6.2.post1\n",
            "cudf-cu12                             25.2.1\n",
            "cudf-polars-cu12                      25.2.2\n",
            "cufflinks                             0.17.3\n",
            "cuml-cu12                             25.2.1\n",
            "cupy-cuda12x                          13.3.0\n",
            "curl_cffi                             0.11.3\n",
            "cuvs-cu12                             25.2.1\n",
            "cvxopt                                1.3.2\n",
            "cvxpy                                 1.6.6\n",
            "cycler                                0.12.1\n",
            "cyipopt                               1.5.0\n",
            "cymem                                 2.0.11\n",
            "Cython                                3.0.12\n",
            "dask                                  2024.12.1\n",
            "dask-cuda                             25.2.0\n",
            "dask-cudf-cu12                        25.2.2\n",
            "dask-expr                             1.1.21\n",
            "dataproc-spark-connect                0.7.5\n",
            "datascience                           0.17.6\n",
            "datasets                              3.6.0\n",
            "db-dtypes                             1.4.3\n",
            "dbus-python                           1.2.18\n",
            "debugpy                               1.8.0\n",
            "decorator                             4.4.2\n",
            "defusedxml                            0.7.1\n",
            "diffusers                             0.33.1\n",
            "dill                                  0.3.7\n",
            "distributed                           2024.12.1\n",
            "distributed-ucxx-cu12                 0.42.0\n",
            "distro                                1.9.0\n",
            "dlib                                  19.24.6\n",
            "dm-tree                               0.1.9\n",
            "docstring_parser                      0.16\n",
            "docutils                              0.21.2\n",
            "dopamine_rl                           4.1.2\n",
            "duckdb                                1.2.2\n",
            "earthengine-api                       1.5.19\n",
            "easydict                              1.13\n",
            "editdistance                          0.8.1\n",
            "eerepr                                0.1.2\n",
            "einops                                0.8.1\n",
            "en_core_web_sm                        3.8.0\n",
            "entrypoints                           0.4\n",
            "et_xmlfile                            2.0.0\n",
            "etils                                 1.12.2\n",
            "etuples                               0.3.9\n",
            "evaluate                              0.4.4\n",
            "Farama-Notifications                  0.0.4\n",
            "fastai                                2.7.19\n",
            "fastapi                               0.115.12\n",
            "fastcore                              1.7.29\n",
            "fastdownload                          0.0.7\n",
            "fastjsonschema                        2.21.1\n",
            "fastprogress                          1.0.3\n",
            "fastrlock                             0.8.3\n",
            "ffmpy                                 0.6.0\n",
            "filelock                              3.18.0\n",
            "firebase-admin                        6.9.0\n",
            "Flask                                 3.1.1\n",
            "flatbuffers                           25.2.10\n",
            "flax                                  0.10.6\n",
            "folium                                0.19.7\n",
            "fonttools                             4.58.4\n",
            "frozendict                            2.4.6\n",
            "frozenlist                            1.7.0\n",
            "fsspec                                2025.3.0\n",
            "future                                1.0.0\n",
            "gast                                  0.6.0\n",
            "gcsfs                                 2025.3.2\n",
            "GDAL                                  3.8.4\n",
            "gdown                                 5.2.0\n",
            "geemap                                0.35.3\n",
            "geocoder                              1.38.1\n",
            "geographiclib                         2.0\n",
            "geopandas                             1.0.1\n",
            "geopy                                 2.4.1\n",
            "gin-config                            0.5.0\n",
            "gitdb                                 4.0.12\n",
            "GitPython                             3.1.44\n",
            "glob2                                 0.7\n",
            "google                                2.0.3\n",
            "google-ai-generativelanguage          0.6.15\n",
            "google-api-core                       2.25.1\n",
            "google-api-python-client              2.172.0\n",
            "google-auth                           2.38.0\n",
            "google-auth-httplib2                  0.2.0\n",
            "google-auth-oauthlib                  1.2.2\n",
            "google-cloud-aiplatform               1.97.0\n",
            "google-cloud-bigquery                 3.34.0\n",
            "google-cloud-bigquery-connection      1.18.3\n",
            "google-cloud-bigquery-storage         2.32.0\n",
            "google-cloud-core                     2.4.3\n",
            "google-cloud-dataproc                 5.20.0\n",
            "google-cloud-datastore                2.21.0\n",
            "google-cloud-firestore                2.21.0\n",
            "google-cloud-functions                1.20.4\n",
            "google-cloud-iam                      2.19.1\n",
            "google-cloud-language                 2.17.2\n",
            "google-cloud-resource-manager         1.14.2\n",
            "google-cloud-spanner                  3.55.0\n",
            "google-cloud-storage                  2.19.0\n",
            "google-cloud-translate                3.20.3\n",
            "google-colab                          1.0.0\n",
            "google-crc32c                         1.7.1\n",
            "google-genai                          1.20.0\n",
            "google-generativeai                   0.8.5\n",
            "google-pasta                          0.2.0\n",
            "google-resumable-media                2.7.2\n",
            "googleapis-common-protos              1.70.0\n",
            "googledrivedownloader                 1.1.0\n",
            "gradio                                5.31.0\n",
            "gradio_client                         1.10.1\n",
            "graphviz                              0.21\n",
            "greenlet                              3.2.3\n",
            "groovy                                0.1.2\n",
            "grpc-google-iam-v1                    0.14.2\n",
            "grpc-interceptor                      0.15.4\n",
            "grpcio                                1.73.0\n",
            "grpcio-status                         1.71.0\n",
            "grpclib                               0.4.8\n",
            "gspread                               6.2.1\n",
            "gspread-dataframe                     4.0.0\n",
            "gym                                   0.25.2\n",
            "gym-notices                           0.0.8\n",
            "gymnasium                             1.1.1\n",
            "h11                                   0.16.0\n",
            "h2                                    4.2.0\n",
            "h5netcdf                              1.6.1\n",
            "h5py                                  3.14.0\n",
            "hdbscan                               0.8.40\n",
            "hf_transfer                           0.1.9\n",
            "hf-xet                                1.1.3\n",
            "highspy                               1.11.0\n",
            "holidays                              0.74\n",
            "holoviews                             1.20.2\n",
            "hpack                                 4.1.0\n",
            "html5lib                              1.1\n",
            "httpcore                              1.0.9\n",
            "httpimport                            1.4.1\n",
            "httplib2                              0.22.0\n",
            "httpx                                 0.28.1\n",
            "huggingface-hub                       0.33.0\n",
            "humanize                              4.12.3\n",
            "hyperframe                            6.1.0\n",
            "hyperopt                              0.2.7\n",
            "ibis-framework                        9.5.0\n",
            "idna                                  3.10\n",
            "imageio                               2.37.0\n",
            "imageio-ffmpeg                        0.6.0\n",
            "imagesize                             1.4.1\n",
            "imbalanced-learn                      0.13.0\n",
            "immutabledict                         4.2.1\n",
            "importlib_metadata                    8.7.0\n",
            "importlib_resources                   6.5.2\n",
            "imutils                               0.5.4\n",
            "inflect                               7.5.0\n",
            "iniconfig                             2.1.0\n",
            "intel-cmplr-lib-ur                    2025.1.1\n",
            "intel-openmp                          2025.1.1\n",
            "ipyevents                             2.0.2\n",
            "ipyfilechooser                        0.6.0\n",
            "ipykernel                             6.17.1\n",
            "ipyleaflet                            0.20.0\n",
            "ipyparallel                           8.8.0\n",
            "ipython                               7.34.0\n",
            "ipython-genutils                      0.2.0\n",
            "ipython-sql                           0.5.0\n",
            "ipytree                               0.2.2\n",
            "ipywidgets                            7.7.1\n",
            "itsdangerous                          2.2.0\n",
            "jaraco.classes                        3.4.0\n",
            "jaraco.context                        6.0.1\n",
            "jaraco.functools                      4.1.0\n",
            "jax                                   0.5.2\n",
            "jax-cuda12-pjrt                       0.5.1\n",
            "jax-cuda12-plugin                     0.5.1\n",
            "jaxlib                                0.5.1\n",
            "jeepney                               0.9.0\n",
            "jieba                                 0.42.1\n",
            "Jinja2                                3.1.6\n",
            "jiter                                 0.10.0\n",
            "joblib                                1.5.1\n",
            "jsonpatch                             1.33\n",
            "jsonpickle                            4.1.1\n",
            "jsonpointer                           3.0.0\n",
            "jsonschema                            4.24.0\n",
            "jsonschema-specifications             2025.4.1\n",
            "jupyter-client                        6.1.12\n",
            "jupyter-console                       6.1.0\n",
            "jupyter_core                          5.8.1\n",
            "jupyter_kernel_gateway                2.5.2\n",
            "jupyter-leaflet                       0.20.0\n",
            "jupyter-server                        1.16.0\n",
            "jupyterlab_pygments                   0.3.0\n",
            "jupyterlab_widgets                    3.0.15\n",
            "jupytext                              1.17.2\n",
            "kaggle                                1.7.4.5\n",
            "kagglehub                             0.3.12\n",
            "keras                                 3.8.0\n",
            "keras-hub                             0.18.1\n",
            "keras-nlp                             0.18.1\n",
            "keyring                               25.6.0\n",
            "keyrings.google-artifactregistry-auth 1.1.2\n",
            "kiwisolver                            1.4.8\n",
            "langchain                             0.3.25\n",
            "langchain-core                        0.3.65\n",
            "langchain-text-splitters              0.3.8\n",
            "langcodes                             3.5.0\n",
            "langsmith                             0.3.45\n",
            "language_data                         1.3.0\n",
            "launchpadlib                          1.10.16\n",
            "lazr.restfulclient                    0.14.4\n",
            "lazr.uri                              1.0.6\n",
            "lazy_loader                           0.4\n",
            "libclang                              18.1.1\n",
            "libcudf-cu12                          25.2.1\n",
            "libcugraph-cu12                       25.2.0\n",
            "libcuml-cu12                          25.2.1\n",
            "libcuvs-cu12                          25.2.1\n",
            "libkvikio-cu12                        25.2.1\n",
            "libpysal                              4.13.0\n",
            "libraft-cu12                          25.2.0\n",
            "librosa                               0.11.0\n",
            "libucx-cu12                           1.18.1\n",
            "libucxx-cu12                          0.42.0\n",
            "lightgbm                              4.5.0\n",
            "linkify-it-py                         2.0.3\n",
            "llvmlite                              0.43.0\n",
            "locket                                1.0.0\n",
            "logical-unification                   0.4.6\n",
            "lxml                                  5.4.0\n",
            "Mako                                  1.1.3\n",
            "marisa-trie                           1.2.1\n",
            "Markdown                              3.8\n",
            "markdown-it-py                        3.0.0\n",
            "MarkupSafe                            3.0.2\n",
            "matplotlib                            3.10.0\n",
            "matplotlib-inline                     0.1.7\n",
            "matplotlib-venn                       1.1.2\n",
            "mdit-py-plugins                       0.4.2\n",
            "mdurl                                 0.1.2\n",
            "miniKanren                            1.0.3\n",
            "missingno                             0.5.2\n",
            "mistune                               3.1.3\n",
            "mizani                                0.13.5\n",
            "mkl                                   2025.0.1\n",
            "ml-dtypes                             0.4.1\n",
            "mlxtend                               0.23.4\n",
            "more-itertools                        10.7.0\n",
            "moviepy                               1.0.3\n",
            "mpmath                                1.3.0\n",
            "msgpack                               1.1.1\n",
            "multidict                             6.4.4\n",
            "multipledispatch                      1.0.0\n",
            "multiprocess                          0.70.15\n",
            "multitasking                          0.0.11\n",
            "murmurhash                            1.0.13\n",
            "music21                               9.3.0\n",
            "namex                                 0.1.0\n",
            "narwhals                              1.43.0\n",
            "natsort                               8.4.0\n",
            "nbclassic                             1.3.1\n",
            "nbclient                              0.10.2\n",
            "nbconvert                             7.16.6\n",
            "nbformat                              5.10.4\n",
            "ndindex                               1.10.0\n",
            "nest-asyncio                          1.6.0\n",
            "networkx                              3.5\n",
            "nibabel                               5.3.2\n",
            "nltk                                  3.9.1\n",
            "notebook                              6.5.7\n",
            "notebook_shim                         0.2.4\n",
            "numba                                 0.60.0\n",
            "numba-cuda                            0.2.0\n",
            "numexpr                               2.11.0\n",
            "numpy                                 2.0.2\n",
            "nvidia-cublas-cu12                    12.4.5.8\n",
            "nvidia-cuda-cupti-cu12                12.4.127\n",
            "nvidia-cuda-nvcc-cu12                 12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                12.4.127\n",
            "nvidia-cuda-runtime-cu12              12.4.127\n",
            "nvidia-cudnn-cu12                     9.1.0.70\n",
            "nvidia-cufft-cu12                     11.2.1.3\n",
            "nvidia-curand-cu12                    10.3.5.147\n",
            "nvidia-cusolver-cu12                  11.6.1.9\n",
            "nvidia-cusparse-cu12                  12.3.1.170\n",
            "nvidia-cusparselt-cu12                0.6.2\n",
            "nvidia-ml-py                          12.575.51\n",
            "nvidia-nccl-cu12                      2.21.5\n",
            "nvidia-nvcomp-cu12                    4.2.0.11\n",
            "nvidia-nvjitlink-cu12                 12.4.127\n",
            "nvidia-nvtx-cu12                      12.4.127\n",
            "nvtx                                  0.2.12\n",
            "nx-cugraph-cu12                       25.2.0\n",
            "oauth2client                          4.1.3\n",
            "oauthlib                              3.2.2\n",
            "omegaconf                             2.3.0\n",
            "openai                                1.86.0\n",
            "opencv-contrib-python                 4.11.0.86\n",
            "opencv-python                         4.11.0.86\n",
            "opencv-python-headless                4.11.0.86\n",
            "openpyxl                              3.1.5\n",
            "opt_einsum                            3.4.0\n",
            "optax                                 0.2.5\n",
            "optree                                0.16.0\n",
            "orbax-checkpoint                      0.11.15\n",
            "orjson                                3.10.18\n",
            "osqp                                  1.0.4\n",
            "packaging                             24.2\n",
            "pandas                                2.2.2\n",
            "pandas-datareader                     0.10.0\n",
            "pandas-gbq                            0.29.1\n",
            "pandas-stubs                          2.2.2.240909\n",
            "pandocfilters                         1.5.1\n",
            "panel                                 1.7.1\n",
            "param                                 2.2.1\n",
            "parso                                 0.8.4\n",
            "parsy                                 2.1\n",
            "partd                                 1.4.2\n",
            "pathlib                               1.0.1\n",
            "patsy                                 1.0.1\n",
            "peewee                                3.18.1\n",
            "peft                                  0.15.2\n",
            "pexpect                               4.9.0\n",
            "pickleshare                           0.7.5\n",
            "pillow                                11.2.1\n",
            "pip                                   24.1.2\n",
            "platformdirs                          4.3.8\n",
            "plotly                                5.24.1\n",
            "plotnine                              0.14.5\n",
            "pluggy                                1.6.0\n",
            "ply                                   3.11\n",
            "polars                                1.21.0\n",
            "pooch                                 1.8.2\n",
            "portpicker                            1.5.2\n",
            "preshed                               3.0.10\n",
            "prettytable                           3.16.0\n",
            "proglog                               0.1.12\n",
            "progressbar2                          4.5.0\n",
            "prometheus_client                     0.22.1\n",
            "promise                               2.3\n",
            "prompt_toolkit                        3.0.51\n",
            "propcache                             0.3.2\n",
            "prophet                               1.1.7\n",
            "proto-plus                            1.26.1\n",
            "protobuf                              5.29.5\n",
            "psutil                                5.9.5\n",
            "psycopg2                              2.9.10\n",
            "ptyprocess                            0.7.0\n",
            "py-cpuinfo                            9.0.0\n",
            "py4j                                  0.10.9.7\n",
            "pyarrow                               18.1.0\n",
            "pyasn1                                0.6.1\n",
            "pyasn1_modules                        0.4.2\n",
            "pycairo                               1.28.0\n",
            "pycocotools                           2.0.10\n",
            "pycparser                             2.22\n",
            "pycryptodomex                         3.23.0\n",
            "pydantic                              2.11.7\n",
            "pydantic_core                         2.33.2\n",
            "pydata-google-auth                    1.9.1\n",
            "pydot                                 3.0.4\n",
            "pydotplus                             2.0.2\n",
            "PyDrive                               1.3.1\n",
            "PyDrive2                              1.21.3\n",
            "pydub                                 0.25.1\n",
            "pyerfa                                2.0.1.5\n",
            "pygame                                2.6.1\n",
            "pygit2                                1.18.0\n",
            "Pygments                              2.19.1\n",
            "PyGObject                             3.42.0\n",
            "PyJWT                                 2.10.1\n",
            "pylibcudf-cu12                        25.2.1\n",
            "pylibcugraph-cu12                     25.2.0\n",
            "pylibraft-cu12                        25.2.0\n",
            "pymc                                  5.23.0\n",
            "pymystem3                             0.2.0\n",
            "pynndescent                           0.5.13\n",
            "pynvjitlink-cu12                      0.6.0\n",
            "pynvml                                12.0.0\n",
            "pyogrio                               0.11.0\n",
            "pyomo                                 6.9.2\n",
            "PyOpenGL                              3.1.9\n",
            "pyOpenSSL                             24.2.1\n",
            "pyparsing                             3.2.3\n",
            "pyperclip                             1.9.0\n",
            "pyproj                                3.7.1\n",
            "pyproject_hooks                       1.2.0\n",
            "pyshp                                 2.3.1\n",
            "PySocks                               1.7.1\n",
            "pyspark                               3.5.1\n",
            "pytensor                              2.31.3\n",
            "pytest                                8.3.5\n",
            "python-apt                            0.0.0\n",
            "python-box                            7.3.2\n",
            "python-dateutil                       2.9.0.post0\n",
            "python-louvain                        0.16\n",
            "python-multipart                      0.0.20\n",
            "python-slugify                        8.0.4\n",
            "python-snappy                         0.7.3\n",
            "python-utils                          3.9.1\n",
            "pytz                                  2025.2\n",
            "pyviz_comms                           3.0.5\n",
            "PyWavelets                            1.8.0\n",
            "PyYAML                                6.0.2\n",
            "pyzmq                                 24.0.1\n",
            "raft-dask-cu12                        25.2.0\n",
            "rapids-dask-dependency                25.2.0\n",
            "ratelim                               0.1.6\n",
            "referencing                           0.36.2\n",
            "regex                                 2024.11.6\n",
            "requests                              2.32.3\n",
            "requests-oauthlib                     2.0.0\n",
            "requests-toolbelt                     1.0.0\n",
            "requirements-parser                   0.9.0\n",
            "rich                                  13.9.4\n",
            "rmm-cu12                              25.2.0\n",
            "roman-numerals-py                     3.1.0\n",
            "rpds-py                               0.25.1\n",
            "rpy2                                  3.5.17\n",
            "rsa                                   4.9.1\n",
            "ruff                                  0.11.13\n",
            "safehttpx                             0.1.6\n",
            "safetensors                           0.5.3\n",
            "scikit-image                          0.25.2\n",
            "scikit-learn                          1.6.1\n",
            "scipy                                 1.15.3\n",
            "scooby                                0.10.1\n",
            "scs                                   3.2.7.post2\n",
            "seaborn                               0.13.2\n",
            "SecretStorage                         3.3.3\n",
            "semantic-version                      2.10.0\n",
            "Send2Trash                            1.8.3\n",
            "sentence-transformers                 4.1.0\n",
            "sentencepiece                         0.2.0\n",
            "sentry-sdk                            2.30.0\n",
            "setproctitle                          1.3.6\n",
            "setuptools                            75.2.0\n",
            "shap                                  0.48.0\n",
            "shapely                               2.1.1\n",
            "shellingham                           1.5.4\n",
            "simple-parsing                        0.1.7\n",
            "simplejson                            3.20.1\n",
            "simsimd                               6.4.9\n",
            "six                                   1.17.0\n",
            "sklearn-compat                        0.1.3\n",
            "sklearn-pandas                        2.2.0\n",
            "slicer                                0.0.8\n",
            "smart-open                            7.1.0\n",
            "smmap                                 5.0.2\n",
            "sniffio                               1.3.1\n",
            "snowballstemmer                       3.0.1\n",
            "sortedcontainers                      2.4.0\n",
            "soundfile                             0.13.1\n",
            "soupsieve                             2.7\n",
            "soxr                                  0.5.0.post1\n",
            "spacy                                 3.8.7\n",
            "spacy-legacy                          3.0.12\n",
            "spacy-loggers                         1.0.5\n",
            "spanner-graph-notebook                1.1.7\n",
            "Sphinx                                8.2.3\n",
            "sphinxcontrib-applehelp               2.0.0\n",
            "sphinxcontrib-devhelp                 2.0.0\n",
            "sphinxcontrib-htmlhelp                2.1.0\n",
            "sphinxcontrib-jsmath                  1.0.1\n",
            "sphinxcontrib-qthelp                  2.0.0\n",
            "sphinxcontrib-serializinghtml         2.0.0\n",
            "SQLAlchemy                            2.0.41\n",
            "sqlglot                               25.20.2\n",
            "sqlparse                              0.5.3\n",
            "srsly                                 2.5.1\n",
            "stanio                                0.5.1\n",
            "starlette                             0.46.2\n",
            "statsmodels                           0.14.4\n",
            "stringzilla                           3.12.5\n",
            "stumpy                                1.13.0\n",
            "sympy                                 1.13.1\n",
            "tables                                3.10.2\n",
            "tabulate                              0.9.0\n",
            "tbb                                   2022.1.0\n",
            "tblib                                 3.1.0\n",
            "tcmlib                                1.3.0\n",
            "tenacity                              9.1.2\n",
            "tensorboard                           2.18.0\n",
            "tensorboard-data-server               0.7.2\n",
            "tensorflow                            2.18.0\n",
            "tensorflow-datasets                   4.9.9\n",
            "tensorflow_decision_forests           1.11.0\n",
            "tensorflow-hub                        0.16.1\n",
            "tensorflow-io-gcs-filesystem          0.37.1\n",
            "tensorflow-metadata                   1.17.1\n",
            "tensorflow-probability                0.25.0\n",
            "tensorflow-text                       2.18.1\n",
            "tensorstore                           0.1.74\n",
            "termcolor                             3.1.0\n",
            "terminado                             0.18.1\n",
            "text-unidecode                        1.3\n",
            "textblob                              0.19.0\n",
            "tf_keras                              2.18.0\n",
            "tf-slim                               1.1.0\n",
            "thinc                                 8.3.6\n",
            "threadpoolctl                         3.6.0\n",
            "tifffile                              2025.6.11\n",
            "tiktoken                              0.9.0\n",
            "timm                                  1.0.15\n",
            "tinycss2                              1.4.0\n",
            "tokenizers                            0.21.1\n",
            "toml                                  0.10.2\n",
            "tomlkit                               0.13.3\n",
            "toolz                                 0.12.1\n",
            "torch                                 2.6.0+cu124\n",
            "torchao                               0.10.0\n",
            "torchaudio                            2.6.0+cu124\n",
            "torchdata                             0.11.0\n",
            "torchsummary                          1.5.1\n",
            "torchtune                             0.6.1\n",
            "torchvision                           0.21.0+cu124\n",
            "tornado                               6.4.2\n",
            "tqdm                                  4.67.1\n",
            "traitlets                             5.7.1\n",
            "traittypes                            0.2.1\n",
            "transformers                          4.52.4\n",
            "treelite                              4.4.1\n",
            "treescope                             0.1.9\n",
            "triton                                3.2.0\n",
            "trl                                   0.19.0\n",
            "tsfresh                               0.21.0\n",
            "tweepy                                4.15.0\n",
            "typeguard                             4.4.3\n",
            "typer                                 0.16.0\n",
            "types-pytz                            2025.2.0.20250516\n",
            "types-setuptools                      80.9.0.20250529\n",
            "typing_extensions                     4.14.0\n",
            "typing-inspection                     0.4.1\n",
            "tzdata                                2025.2\n",
            "tzlocal                               5.3.1\n",
            "uc-micro-py                           1.0.3\n",
            "ucx-py-cu12                           0.42.0\n",
            "ucxx-cu12                             0.42.0\n",
            "umap-learn                            0.5.7\n",
            "umf                                   0.10.0\n",
            "uritemplate                           4.2.0\n",
            "urllib3                               2.4.0\n",
            "uvicorn                               0.34.3\n",
            "vega-datasets                         0.9.0\n",
            "wadllib                               1.3.6\n",
            "wandb                                 0.20.1\n",
            "wasabi                                1.1.3\n",
            "wcwidth                               0.2.13\n",
            "weasel                                0.4.1\n",
            "webcolors                             24.11.1\n",
            "webencodings                          0.5.1\n",
            "websocket-client                      1.8.0\n",
            "websockets                            15.0.1\n",
            "Werkzeug                              3.1.3\n",
            "wheel                                 0.45.1\n",
            "widgetsnbextension                    3.6.10\n",
            "wordcloud                             1.9.4\n",
            "wrapt                                 1.17.2\n",
            "wurlitzer                             3.1.1\n",
            "xarray                                2025.3.1\n",
            "xarray-einstats                       0.9.0\n",
            "xgboost                               2.1.4\n",
            "xlrd                                  2.0.2\n",
            "xxhash                                3.5.0\n",
            "xyzservices                           2025.4.0\n",
            "yarl                                  1.20.1\n",
            "ydf                                   0.12.0\n",
            "yellowbrick                           1.5\n",
            "yfinance                              0.2.63\n",
            "zict                                  3.0.0\n",
            "zipp                                  3.23.0\n",
            "zstandard                             0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ITxDrzMOWDBr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "API_TOKEN = userdata.get('API_TOKEN')\n",
        "login(token=API_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIXXvMnWDBs"
      },
      "source": [
        "# Base model from HUB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRO0HlFJWDBs"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "7c2b15cb15754bd6b6fe52d59dccf005",
            "97b58a7757b44d3fb06bb77454ac0880",
            "d75370b7b8dd43d590eefb029a73e257",
            "fdcdc1c38af942c9be6f0b64ae39310d",
            "931677d3f9124466bcde9e2b0a8a253e",
            "a02b4c3a4c654d9e83bce5147c772dd7",
            "dd9baae3b97d4b95b817bb33dfc659f7",
            "7aa0b949157649b9ba3bc3757bb42c30",
            "e92815890e984c508f20fdd11ef0c1d3",
            "d1ca3cc1ab5c410485addb4b2e938715",
            "5768129d3b0c46c791f66fa62f2d279d",
            "94412a9ee3794a26af42d69598a14e39",
            "b7ac4400709b4eea966d735002482872",
            "12a8117b3fb34048b328331877edd2ce",
            "94cc1531235f4c31a9aacff6a826f330",
            "e7544f2cadc54dff9c85b151da88af89",
            "b3ef9d7d48ab4591a9a12c6c78828a64",
            "bc134b3fb678409f99c63cfc0a47c252",
            "bdf527e99eb0495aa12843f6a96a8515",
            "f4e3fc438640484e8373d048319ab2eb",
            "50a30e6edc134049a29b755efaccf94c",
            "9766f84c14144732b97bb11745661623",
            "f7c19acded284cd29d666eab1167999a",
            "916823760e144866ac2e0c174d7154d8",
            "5d53fbc5e9d14b4ea6b4b1276e3fd43e",
            "06a1b14330064f3aae1cf1a88573f2d0",
            "6a30a2db2fa5488fa8e896e10614e368",
            "9da3c4f5fcf249fe855346bc48696737",
            "abefc04c6a6f44a48ed88ab4048ff84a",
            "19b9884786214b7aabd41c16c308fff0",
            "008a81a1f2244f9b94eb2b2eb43294e6",
            "47c2af17a2de4ca1a115b7cb7e79da42",
            "29a5e9fd58fc44139156490d36134384",
            "3898571eeed04fbb87d043aa9a7efb3e",
            "f4ba719fff77423884e50551a77aa6b0",
            "31dea37b2c4e4e9e89674104fefdad98",
            "8d89fea593334ae6bedd0e29d0def50d",
            "9f25c6310f94434ba5d83abd464c72ce",
            "771f072a7dcb4da9b9b5dffda2d657f5",
            "62cd2d86cf2d4daebd789077c60f8ec6",
            "be7179b5e8924f0e853523346a23067a",
            "b64bbefef8df4ff58de3efc387a2f0a6",
            "3ea4d33f5db644f6b3229236a8244a61",
            "9c368abbb7d5495287670e090ffe3299",
            "b4e3d676a0bf498c87e67305513516c6",
            "4e5a62645a984953855601f8ceffb375",
            "02dd8de73885415d81ac2023bdccf8ee",
            "241f7af51e4746e8b9397604ac670ef3",
            "a5700e1af72d41209c1b5ab8b94b58ba",
            "e0e0ae7a10d74cc69c89378526c6821e",
            "79e50b55b21a4fafa1acfd3ff675c1b1",
            "9218f5a996cf455caa4003914659dfe9",
            "055311aced6b482483f9818f2316c491",
            "fff0de1de04c46008962f6dace820988",
            "859607149ba94d99bb3414da397a3f14",
            "b8501697c85b41d194e806dc5d48a6f9",
            "736b7c69ef754bd796f57e4fd0ca293d",
            "fb297b9943c1460595988cb7c7bf32ee",
            "6194bf8506c745279819d762ef0426fe",
            "ce8754ea2cab46dd94a46937123fbc1d",
            "40f5b8151bd0450cadc63fbbefc27ef4",
            "4a6d7e7f667d4ec992ce46cb2c6e430b",
            "d99acb6506f943c8aefbdce5fa15bed4",
            "612d2cc91ddd4eca8d4f02eb7cf0fc22",
            "b584a4bc8ad84019854250a85496c413",
            "a9f216aa4d28498bacdb6dd41cb9fb1e"
          ]
        },
        "id": "5TImhIcfWDBs",
        "outputId": "f007f6a2-8ae5-4cfe-c145-657c69412ecd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c2b15cb15754bd6b6fe52d59dccf005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94412a9ee3794a26af42d69598a14e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7c19acded284cd29d666eab1167999a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3898571eeed04fbb87d043aa9a7efb3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4e3d676a0bf498c87e67305513516c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8501697c85b41d194e806dc5d48a6f9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# Merge LoRA adapters with base model\n",
        "# lama has problem that you need to ask for access repositories of meta\n",
        "#model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# Quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"cuda\",\n",
        ")\n",
        "print(base_model.get_input_embeddings())\n",
        "print(base_model.get_output_embeddings())\n",
        "print(\"Model Vocabulary Size:\", base_model.config.vocab_size)\n",
        "\n",
        "\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "print(\"before\", len(base_tokenizer))\n",
        "base_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
        "print(\"after\", len(base_tokenizer))\n",
        "\n",
        "# viz https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/llama3#usage-tips\n",
        "print(\"before 2\", base_model.config.pad_token_id)\n",
        "base_model.config.pad_token_id = base_tokenizer.pad_token_id\n",
        "print(\"after 2\", base_model.config.pad_token_id)\n",
        "\n",
        "print(\"Model Vocabulary Size:\", base_model.config.vocab_size)\n",
        "base_model.resize_token_embeddings(len(base_tokenizer))\n",
        "print(\"Model Vocabulary Size:\", base_model.config.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYfYQacCWDBs"
      },
      "source": [
        "Log model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQmRVzUHWDBs",
        "outputId": "dee874b5-fece-4ad1-d782-a73fe8a4226e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Model---\n",
            "Type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
            "Architecture: LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128257, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128257, bias=False)\n",
            ")\n",
            "Config: LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128256,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128257\n",
            "}\n",
            "\n",
            "Model Vocabulary Size: 128257\n",
            "Input embeddings:\n",
            "Embedding(128257, 4096)\n",
            "Output embeddings:\n",
            "Linear(in_features=4096, out_features=128257, bias=False)\n",
            "---Tokenzier---\n",
            "Type: <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n",
            "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<pad>'}\n",
            "All tokens count: 128257\n",
            "Padding side: right\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print(\"---Model---\")\n",
        "print(\"Type:\", type(base_model))\n",
        "print(\"Architecture:\", base_model)\n",
        "print(\"Config:\", base_model.config)\n",
        "print(\"Model Vocabulary Size:\", base_model.config.vocab_size)\n",
        "print(\"Input embeddings:\")\n",
        "print(base_model.get_input_embeddings())\n",
        "print(\"Output embeddings:\")\n",
        "print(base_model.get_output_embeddings())\n",
        "\n",
        "# Tokenizer\n",
        "print(\"---Tokenzier---\")\n",
        "print(\"Type:\", type(base_tokenizer))\n",
        "# print(tokenizer_loaded)\n",
        "print(\"Special tokens:\", base_tokenizer.special_tokens_map)\n",
        "print(\"All tokens count:\", len(base_tokenizer))\n",
        "print(\"Padding side:\", base_tokenizer.padding_side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KnDLrcgWDBs"
      },
      "source": [
        "### Test the model - OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yYln6cjWDBs"
      },
      "source": [
        "#### via Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "GPq137PDWDBt",
        "outputId": "f07a1872-7474-4d60-c3ba-bb7b7c053801"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1938262257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a pipeline for text generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m my_pipeline = pipeline(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "my_pipeline = pipeline(\n",
        "    \"text-generation\", model=base_model, tokenizer=base_tokenizer, max_length=300\n",
        ")\n",
        "\n",
        "result = my_pipeline(\"What is AutoGen in abstract?\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYGO7setWDBt"
      },
      "source": [
        "#### via Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4D3Se6oWDBt"
      },
      "outputs": [],
      "source": [
        "# Tokenize the prompt\n",
        "# input_ids = base_tokenizer.encode(\n",
        "#     \"What is AutoGen in abstract?\", return_tensors=\"pt\"\n",
        "# ).to(\"cuda\")\n",
        "# print(input_ids)\n",
        "\n",
        "chat = [{\"role\": \"user\", \"content\": \"What is AutoGen in abstract?\"}]\n",
        "input_ids = base_tokenizer.apply_chat_template(chat, return_tensors ='pt').to(\"cuda\")\n",
        "print(input_ids)\n",
        "\n",
        "# Generate text\n",
        "result = base_model.generate(input_ids, max_length=300)\n",
        "print(result)\n",
        "\n",
        "# Decode and print the generated text\n",
        "output_text = base_tokenizer.decode(result[0])\n",
        "print(\"Answer:\")\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsV-42YzWDBt"
      },
      "source": [
        "### Save the model (to disk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOV697KwWDBt",
        "outputId": "b0f3ff18-3ad5-4c3e-a1ae-93f144d33cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('SAVED_MODEL/tokenizer_config.json',\n",
              " 'SAVED_MODEL/special_tokens_map.json',\n",
              " 'SAVED_MODEL/tokenizer.json')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model.save_pretrained(\"SAVED_MODEL\")\n",
        "\n",
        "base_tokenizer.save_pretrained(\"SAVED_MODEL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhs1L1vUWDBt"
      },
      "source": [
        "### Push the model (from HUB )to HUB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f58905322baa446aacb9ce91e7d5a4a9",
            "f4ef63c690804293b176577b0afc1f20",
            "c58ef0b4d707470eb26fa3459dfd488b",
            "a1772d290869465d827c3317f4b05a13"
          ]
        },
        "id": "q0SyJht2WDBt",
        "outputId": "2bdf056e-9e49-439d-e7f2-e977c28b1f25"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f58905322baa446aacb9ce91e7d5a4a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ef63c690804293b176577b0afc1f20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c58ef0b4d707470eb26fa3459dfd488b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1772d290869465d827c3317f4b05a13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/lukaskellerstein/my-base-llama-4bit-from-hub/commit/afd77e4b6e548a7c58e60486c1d894ba9ff1edda', commit_message='Upload tokenizer', commit_description='', oid='afd77e4b6e548a7c58e60486c1d894ba9ff1edda', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model.push_to_hub(\n",
        "    repo_id=\"lukaskellerstein/my-base-llama-4bit-from-hub\",\n",
        "    token=API_TOKEN,\n",
        ")\n",
        "base_tokenizer.push_to_hub(\n",
        "    repo_id=\"lukaskellerstein/my-base-llama-4bit-from-hub\",\n",
        "    token=API_TOKEN,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NwgzFBAWDBt"
      },
      "source": [
        "# Hub model from HUB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xc9gXEFWDBt"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "86be6eed6c2644adb78b09978016fb93",
            "38ae325f48144f75b3bfd1e0f471446c",
            "d7242ea24615414980a365cb0eca2185",
            "bf23347219cc4fbfaee45a6fe71ffab4",
            "811c7678f5824a7994ba500290acf235",
            "fb7f8e96e3da45c0917dd3c11242ccf1",
            "268bd3d533a54835a381973749aae2dd",
            "b953efa5cf2c4b7fb62fee2c9856ad6b",
            "1b4f8e6c18fe4c6a9b059f10f0952c05",
            "9d39be303cea4a408ee7149613bae2ea"
          ]
        },
        "id": "dX1SicAiWDBt",
        "outputId": "0270b0d8-5eda-4efb-adc5-b5b03f5ae1e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86be6eed6c2644adb78b09978016fb93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38ae325f48144f75b3bfd1e0f471446c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7242ea24615414980a365cb0eca2185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf23347219cc4fbfaee45a6fe71ffab4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "811c7678f5824a7994ba500290acf235",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb7f8e96e3da45c0917dd3c11242ccf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "268bd3d533a54835a381973749aae2dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b953efa5cf2c4b7fb62fee2c9856ad6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4f8e6c18fe4c6a9b059f10f0952c05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d39be303cea4a408ee7149613bae2ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_hub_loaded_from_hub = AutoModelForCausalLM.from_pretrained(\n",
        "    \"lukaskellerstein/my-base-llama-4bit-from-hub\", device_map=\"auto\"\n",
        ")\n",
        "tokenizer_hub_loaded_from_hub = AutoTokenizer.from_pretrained(\n",
        "    \"lukaskellerstein/my-base-llama-4bit-from-hub\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9jQrUl8WDBt"
      },
      "source": [
        "Log model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi7xOlr9WDBt",
        "outputId": "e7500a26-17fb-4cbf-da92-ab232938fd41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Model---\n",
            "Type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
            "Architecture: LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128257, 4096, padding_idx=128256)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128257, bias=False)\n",
            ")\n",
            "Config: LlamaConfig {\n",
            "  \"_name_or_path\": \"lukaskellerstein/my-base-llama-4bit-from-hub\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128256,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128257\n",
            "}\n",
            "\n",
            "Model Vocabulary Size: 128257\n",
            "Input embeddings:\n",
            "Embedding(128257, 4096, padding_idx=128256)\n",
            "Output embeddings:\n",
            "Linear(in_features=4096, out_features=128257, bias=False)\n",
            "---Tokenzier---\n",
            "Type: <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n",
            "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<pad>'}\n",
            "All tokens count: 128257\n",
            "Padding side: right\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print(\"---Model---\")\n",
        "print(\"Type:\", type(model_hub_loaded_from_hub))\n",
        "print(\"Architecture:\", model_hub_loaded_from_hub)\n",
        "print(\"Config:\", model_hub_loaded_from_hub.config)\n",
        "print(\"Model Vocabulary Size:\", model_hub_loaded_from_hub.config.vocab_size)\n",
        "print(\"Input embeddings:\")\n",
        "print(model_hub_loaded_from_hub.get_input_embeddings())\n",
        "print(\"Output embeddings:\")\n",
        "print(model_hub_loaded_from_hub.get_output_embeddings())\n",
        "\n",
        "# Tokenizer\n",
        "print(\"---Tokenzier---\")\n",
        "print(\"Type:\", type(tokenizer_hub_loaded_from_hub))\n",
        "# print(tokenizer_loaded)\n",
        "print(\"Special tokens:\", tokenizer_hub_loaded_from_hub.special_tokens_map)\n",
        "print(\"All tokens count:\", len(tokenizer_hub_loaded_from_hub))\n",
        "print(\"Padding side:\", tokenizer_hub_loaded_from_hub.padding_side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "280t_2HQWDBu"
      },
      "source": [
        "### Test the model - OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJsyEKwUWDBu"
      },
      "source": [
        "#### via Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXJIapZWDBu",
        "outputId": "914ee746-3c24-4ebe-a192-a66173615359"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'What is AutoGen in abstract?azorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazor'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "my_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_hub_loaded_from_hub,\n",
        "    tokenizer=tokenizer_hub_loaded_from_hub,\n",
        "    max_length=300,\n",
        ")\n",
        "\n",
        "result = my_pipeline(\"What is AutoGen in abstract?\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQOs1ypWDBu"
      },
      "source": [
        "#### via Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE9tkX7qWDBu",
        "outputId": "540b6bfb-ff12-4a04-971b-b3212192df6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009]], device='cuda:0')\n",
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009, 128006,  78191, 128007,    271,  13556,\n",
            "          10172,    374,    264,   3241,   5507,    430,   9651,  27983,  28725,\n",
            "           1787,   2082,     11,   1778,    439,   4342,   3626,     11,   7557,\n",
            "           7346,     11,    323,   1023,  14054,   2082,     11,    369,    264,\n",
            "           3241,   2447,     13,   1102,    374,   6319,    311,   3665,  13707,\n",
            "            892,    323,   8108,    279,   3392,    315,  59177,  11058,    814,\n",
            "           1205,    311,    656,    382,  13556,  10172,   5829,    264,   3896,\n",
            "           6108,   5603,     11,   1405,    264,    743,    315,  20506,    374,\n",
            "           1511,    311,   7068,    279,  28725,   1787,   2082,     13,    578,\n",
            "          20506,    527,   5439,    304,    264,   4382,     11,   1495,   6108,\n",
            "           4221,    323,    649,    387,  32789,    311,   5052,    279,   3230,\n",
            "           3966,    315,    264,   2447,    382,  13556,  10172,    649,    387,\n",
            "           1511,    311,   7068,    264,   7029,   2134,    315,  28725,   1787,\n",
            "           2082,     11,   2737,   1473,      9,  12376,   3626,    369,    356,\n",
            "            323,    356,   1044,   7620,    198,      9,   7557,   7346,    369,\n",
            "           4857,    323,  55320,   2082,    198,      9,  45565,   3626,     11,\n",
            "           1778,    439,    893,   6959,    323,   9492,   9904,    198,      9,\n",
            "          12499,   3626,     11,   1778,    439,  12138,    477,   4823,   3626,\n",
            "            198,      9,   1628,   1690,   1023,   4595,    315,  28725,   1787,\n",
            "           2082,    271,   1383,   1701,   9156,  10172,     11,  13707,    649,\n",
            "           5357,    389,   4477,    279,   6332,  12496,    315,    872,   2068,\n",
            "             11,   4856,   1109,  10374,    892,    389,  59177,     11,  69782,\n",
            "           9256,   1093,  24038,  28725,   1787,   2082,     13, 128009]],\n",
            "       device='cuda:0')\n",
            "Answer:\n",
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is AutoGen in abstract?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "AutoGen is a software tool that automatically generates boilerplate code, such as header files, Makefiles, and other infrastructure code, for a software project. It is designed to save developers time and reduce the amount of repetitive coding they need to do.\n",
            "\n",
            "AutoGen uses a template-based approach, where a set of templates is used to generate the boilerplate code. The templates are written in a simple, text-based language and can be customized to fit the specific needs of a project.\n",
            "\n",
            "AutoGen can be used to generate a wide range of boilerplate code, including:\n",
            "\n",
            "* Header files for C and C++ programs\n",
            "* Makefiles for building and compiling code\n",
            "* Documentation files, such as man pages and HTML documentation\n",
            "* Configuration files, such as XML or JSON files\n",
            "* And many other types of boilerplate code\n",
            "\n",
            "By using AutoGen, developers can focus on writing the core logic of their program, rather than spending time on repetitive, mundane tasks like generating boilerplate code.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the prompt\n",
        "# input_ids = tokenizer_hub_loaded_from_hub.encode(\n",
        "#     \"What is AutoGen in abstract?\", return_tensors=\"pt\"\n",
        "# )\n",
        "# print(input_ids)\n",
        "\n",
        "chat = [{\"role\": \"user\", \"content\": \"What is AutoGen in abstract?\"}]\n",
        "input_ids = base_tokenizer.apply_chat_template(chat, return_tensors ='pt').to(\"cuda\")\n",
        "print(input_ids)\n",
        "\n",
        "# Generate text\n",
        "result = model_hub_loaded_from_hub.generate(input_ids, max_length=300)\n",
        "print(result)\n",
        "\n",
        "# Decode and print the generated text\n",
        "output_text = tokenizer_hub_loaded_from_hub.decode(result[0])\n",
        "print(\"Answer:\")\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf7D1T3bWDBu"
      },
      "source": [
        "# Base model from DISK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTcnhKZZWDBu"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2ec23b0287514c068ec54ecdb6a1380a"
          ]
        },
        "id": "XjoC4aySWDBu",
        "outputId": "d6e88941-6b3e-42f2-e447-a76443ec62dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ec23b0287514c068ec54ecdb6a1380a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_loaded = AutoModelForCausalLM.from_pretrained(\n",
        "    \"SAVED_MODEL\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"cuda\",\n",
        ")\n",
        "\n",
        "tokenizer_loaded = AutoTokenizer.from_pretrained(\"SAVED_MODEL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZeivMjvWDBu"
      },
      "source": [
        "Log model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2j7GMMHWDBu",
        "outputId": "29f6d7c2-a678-464b-8bdd-c1c3aa95923c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Model---\n",
            "Type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
            "Architecture: LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128257, 4096, padding_idx=128256)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128257, bias=False)\n",
            ")\n",
            "Config: LlamaConfig {\n",
            "  \"_name_or_path\": \"SAVED_MODEL\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128256,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128257\n",
            "}\n",
            "\n",
            "Model Vocabulary Size: 128257\n",
            "Input embeddings:\n",
            "Embedding(128257, 4096, padding_idx=128256)\n",
            "Output embeddings:\n",
            "Linear(in_features=4096, out_features=128257, bias=False)\n",
            "---Tokenzier---\n",
            "Type: <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n",
            "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<pad>'}\n",
            "All tokens count: 128257\n",
            "Padding side: right\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print(\"---Model---\")\n",
        "print(\"Type:\", type(model_loaded))\n",
        "print(\"Architecture:\", model_loaded)\n",
        "print(\"Config:\", model_loaded.config)\n",
        "print(\"Model Vocabulary Size:\", model_loaded.config.vocab_size)\n",
        "print(\"Input embeddings:\")\n",
        "print(model_loaded.get_input_embeddings())\n",
        "print(\"Output embeddings:\")\n",
        "print(model_loaded.get_output_embeddings())\n",
        "\n",
        "# Tokenizer\n",
        "print(\"---Tokenzier---\")\n",
        "print(\"Type:\", type(tokenizer_loaded))\n",
        "# print(tokenizer_loaded)\n",
        "print(\"Special tokens:\", tokenizer_loaded.special_tokens_map)\n",
        "print(\"All tokens count:\", len(tokenizer_loaded))\n",
        "print(\"Padding side:\", tokenizer_loaded.padding_side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRZ2N-yTWDBu"
      },
      "source": [
        "### Test the model - OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPSz8T_sWDBu"
      },
      "source": [
        "#### via Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fo_vH6cWDBu",
        "outputId": "2a0bac31-b81d-41bb-f06a-022713f86f23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'What is AutoGen in abstract?azorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazorazor'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "my_pipeline = pipeline(\n",
        "    \"text-generation\", model=model_loaded, tokenizer=tokenizer_loaded, max_length=300\n",
        ")\n",
        "\n",
        "result = my_pipeline(\"What is AutoGen in abstract?\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRbt81JoWDBu"
      },
      "source": [
        "#### via Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5HFCp4OWDBu",
        "outputId": "a59e5472-bb2e-483d-c624-7748d2192adb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009]], device='cuda:0')\n",
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009, 128006,  78191, 128007,    271,  13556,\n",
            "          10172,    374,    459,   1825,  31874,   5507,    430,   9651,  27983,\n",
            "          28725,   1787,   2082,    369,   5370,  15840,  15823,     11,   2737,\n",
            "            356,     11,    356,  23240,   8102,     11,    323,   3885,     13,\n",
            "           1102,   5829,    264,   4382,     11,   9632,   1413,  20047,    311,\n",
            "           7664,    279,   2082,   9659,   1920,     11,  10923,  13707,    311,\n",
            "           5357,    389,    279,  12496,    315,    872,   2082,   4856,   1109,\n",
            "            279,  66838,   3465,    315,   4477,  59177,  28725,   1787,   2082,\n",
            "            382,    644,  28591,     11,   9156,  10172,  14385,    439,    264,\n",
            "           2082,  14143,     11,   4737,    304,    264,    743,    315,  20506,\n",
            "            323,    264,   6683,   1052,    439,   1988,     11,    323,  17843,\n",
            "            264,   4686,     11,   3318,   6710,    315,   2082,    439,   2612,\n",
            "             13,   1115,   2082,    649,   2997,   2574,   1093,   1473,      9,\n",
            "           5830,  16068,    323,  39437,    198,      9,   3308,  17931,    323,\n",
            "           4562,   5865,    198,      9,   2956,  14726,    323,  26249,    198,\n",
            "              9,   4703,  11850,    323,   4788,  24717,    198,      9,   1628,\n",
            "           1790,    810,   2268,   1383,   5113,   1113,    279,   9659,    315,\n",
            "          28725,   1787,   2082,     11,   9156,  10172,   8779,  13707,   1473,\n",
            "              9,  10467,    892,    323,   5149,    198,      9,  53253,   6103,\n",
            "            323,  92922,    198,      9,  65184,   2082,   4367,    323,  10519,\n",
            "           2968,    198,      9,  26891,    389,    279,  12496,    323,  15293,\n",
            "            315,    872,   2082,    271,  28589,     11,   9156,  10172,    374,\n",
            "            264,   8147,   5507,    430,    649,  82703,    279,   4500,   1920,\n",
            "            323,   1520,  13707,   3350,    810,  11297,     11,   7524,     11,\n",
            "            323,  10519,    481,   2082,     13, 128009]], device='cuda:0')\n",
            "Answer:\n",
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is AutoGen in abstract?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "AutoGen is an open-source tool that automatically generates boilerplate code for various programming languages, including C, C++, Java, and others. It uses a simple, declarative syntax to describe the code generation process, allowing developers to focus on the logic of their code rather than the tedious task of writing repetitive boilerplate code.\n",
            "\n",
            "In essence, AutoGen acts as a code generator, taking in a set of templates and a configuration file as input, and producing a complete, working piece of code as output. This code can include things like:\n",
            "\n",
            "* Function declarations and implementations\n",
            "* Class definitions and member functions\n",
            "* Data structures and algorithms\n",
            "* Error handling and exception mechanisms\n",
            "* And much more!\n",
            "\n",
            "By automating the generation of boilerplate code, AutoGen helps developers:\n",
            "\n",
            "* Save time and effort\n",
            "* Reduce errors and inconsistencies\n",
            "* Improve code quality and maintainability\n",
            "* Focus on the logic and functionality of their code\n",
            "\n",
            "Overall, AutoGen is a powerful tool that can streamline the development process and help developers write more efficient, effective, and maintainable code.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the prompt\n",
        "# input_ids = tokenizer_loaded.encode(\n",
        "#     \"What is AutoGen in abstract?\", return_tensors=\"pt\"\n",
        "# ).to(\"cuda\")\n",
        "# print(input_ids)\n",
        "\n",
        "chat = [{\"role\": \"user\", \"content\": \"What is AutoGen in abstract?\"}]\n",
        "input_ids = tokenizer_loaded.apply_chat_template(chat, return_tensors ='pt').to(\"cuda\")\n",
        "print(input_ids)\n",
        "\n",
        "# Generate text\n",
        "result = model_loaded.generate(input_ids, max_length=1000)\n",
        "print(result)\n",
        "\n",
        "# Decode and print the generated text\n",
        "output_text = tokenizer_loaded.decode(result[0])\n",
        "print(\"Answer:\")\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XblTrUeLWDBu"
      },
      "source": [
        "### Push my base model from DISK to HUB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f3255d1e673d469da15b9dc29fc5ed40",
            "276b554e4f054965aad7cbe9dd721b29",
            "fc92922b591b4b7b9b2e42c111f974be",
            "5ca99d89ca4c48eeb4119dd012bdd721"
          ]
        },
        "id": "SJABXk-YWDBu",
        "outputId": "26a4cf24-0950-44e8-9723-cd7c10b021df"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3255d1e673d469da15b9dc29fc5ed40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "276b554e4f054965aad7cbe9dd721b29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc92922b591b4b7b9b2e42c111f974be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ca99d89ca4c48eeb4119dd012bdd721",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/lukaskellerstein/my-base-llama-8bit-from-disk/commit/54c3cc2036ee76b63dfb0a31f89eae24b4f694ae', commit_message='Upload tokenizer', commit_description='', oid='54c3cc2036ee76b63dfb0a31f89eae24b4f694ae', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_loaded.push_to_hub(\n",
        "    repo_id=\"lukaskellerstein/my-base-llama-8bit-from-disk\",\n",
        "    token=API_TOKEN,\n",
        ")\n",
        "tokenizer_loaded.push_to_hub(\n",
        "    repo_id=\"lukaskellerstein/my-base-llama-8bit-from-disk\",\n",
        "    token=API_TOKEN,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBht9IGUWDBv"
      },
      "source": [
        "# Disk model from HUB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZnW499hWDBv"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "467f3e71c2b54fdfa66fac5574d04292",
            "38b97766b946433a8a838545690aa7a1",
            "cb5cef95235d4f9e8529ad790bd39078",
            "80c76d4bf7554ed785f8351a234b2338",
            "65f3f51b1a884e7abef01168dfcbbe14",
            "803d1f94bf8c476f8e8b91794a7d7818",
            "071dc7866d694fe6b97f63e899cd1d1a",
            "54a3aa6d0c924dadb59351352e9a0998",
            "7f3d6e41c35a46e381d970ffb6181b9a",
            "90227c5a489049f581615529019066d0"
          ]
        },
        "id": "cK6DaU3-WDBv",
        "outputId": "9df4c131-2619-496b-b857-2e18039334e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "467f3e71c2b54fdfa66fac5574d04292",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38b97766b946433a8a838545690aa7a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5cef95235d4f9e8529ad790bd39078",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80c76d4bf7554ed785f8351a234b2338",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f3f51b1a884e7abef01168dfcbbe14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803d1f94bf8c476f8e8b91794a7d7818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "071dc7866d694fe6b97f63e899cd1d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54a3aa6d0c924dadb59351352e9a0998",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f3d6e41c35a46e381d970ffb6181b9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90227c5a489049f581615529019066d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_loaded_fromHF = AutoModelForCausalLM.from_pretrained(\n",
        "    \"lukaskellerstein/my-base-llama-4bit-from-disk\", device_map=\"auto\"\n",
        ")\n",
        "tokenizer_loaded_fromHF = AutoTokenizer.from_pretrained(\n",
        "    \"lukaskellerstein/my-base-llama-4bit-from-disk\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgnTGQ5EWDBv"
      },
      "source": [
        "Log model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8Df3y7cWDBv",
        "outputId": "90326d71-caec-4a30-cdb8-84f372983d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Model---\n",
            "Type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
            "Architecture: LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128257, 4096, padding_idx=128256)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128257, bias=False)\n",
            ")\n",
            "Config: LlamaConfig {\n",
            "  \"_name_or_path\": \"lukaskellerstein/my-base-llama-8bit-from-disk\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128009,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128256,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128257\n",
            "}\n",
            "\n",
            "Model Vocabulary Size: 128257\n",
            "Input embeddings:\n",
            "Embedding(128257, 4096, padding_idx=128256)\n",
            "Output embeddings:\n",
            "Linear(in_features=4096, out_features=128257, bias=False)\n",
            "---Tokenzier---\n",
            "Type: <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>\n",
            "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<pad>'}\n",
            "All tokens count: 128257\n",
            "Padding side: right\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print(\"---Model---\")\n",
        "print(\"Type:\", type(model_loaded_fromHF))\n",
        "print(\"Architecture:\", model_loaded_fromHF)\n",
        "print(\"Config:\", model_loaded_fromHF.config)\n",
        "print(\"Model Vocabulary Size:\", model_loaded_fromHF.config.vocab_size)\n",
        "print(\"Input embeddings:\")\n",
        "print(model_loaded_fromHF.get_input_embeddings())\n",
        "print(\"Output embeddings:\")\n",
        "print(model_loaded_fromHF.get_output_embeddings())\n",
        "\n",
        "# Tokenizer\n",
        "print(\"---Tokenzier---\")\n",
        "print(\"Type:\", type(tokenizer_loaded_fromHF))\n",
        "# print(tokenizer_loaded)\n",
        "print(\"Special tokens:\", tokenizer_loaded_fromHF.special_tokens_map)\n",
        "print(\"All tokens count:\", len(tokenizer_loaded_fromHF))\n",
        "print(\"Padding side:\", tokenizer_loaded_fromHF.padding_side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQTcPorxWDBv"
      },
      "source": [
        "###  Test the model - OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxJF0FgsWDBv"
      },
      "source": [
        "#### via Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbFtmx6YWDBw",
        "outputId": "7a006088-0dd6-4919-c077-ba77c6e8e0c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'What is AutoGen in abstract?osuosuosudbaounderounderstounderamageounderstounderoundingounderounder.posterdbaounder-partamageWERounderosuoundingamage.posterbowerosubowerosuounder Ampounderosu Youndingblank Amp.posterounder-partounderounderosuesty.poster TREEnico Amp.poster.posteraldoaldo.poster Amp Topsestyestyestybowerosu.posterdba.posterounderounder.compress.poster Ampounderaldo.poster Amp.poster Younderaldoaldo.poster Ampensaestyensaescapingkbd.poster Ampblankounderesty.posterounderblank.posterounder TREE.poster-partounderounder.compressblankounderblank Younder.posterkbdounder.posterounderesty Amp Y.poster_EMITtsy.poster.posteresty chargeounder Tankstsy.posternico-partescapingesty.poster  esty TREE.posterensaopic.posterblankesty Tanks_EMIT Tanks Tanksesty Tanksestyestyopicoundertsy_EMITesty_EMITnico kbd_EMITesty  Y_EMIT_EMITopic _EMIT.postertsykbd_EMIT_EMIT_EMIT Tanks_EMITkbdandlenicoescaping_EMITesty.posternico.poster.postertsy.poster_EMITesty'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "my_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_loaded_fromHF,\n",
        "    tokenizer=tokenizer_loaded_fromHF,\n",
        "    max_length=300,\n",
        ")\n",
        "\n",
        "result = my_pipeline(\"What is AutoGen in abstract?\")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54KZh6aKWDBw"
      },
      "source": [
        "#### via Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOJLP2YoWDBw",
        "outputId": "e0155dbb-ab47-45b5-dc42-7227728d372b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009]], device='cuda:0')\n",
            "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,   9156,  10172,\n",
            "            304,   8278,     30, 128009, 128006,  78191, 128007,    271,  13556,\n",
            "          10172,    374,    459,   1825,  31874,   5507,    430,  27983,  28725,\n",
            "           1787,   2082,    369,   5370,  15840,  15823,     11,   2737,    356,\n",
            "             11,    356,  23240,   8102,     11,  13325,     11,    323,   3885,\n",
            "             13,   1102,    596,   6319,    311,  69711,    279,   9886,    315,\n",
            "          59177,     11,  69782,   2082,    430,    374,   3629,   2631,    304,\n",
            "           3241,   4500,     11,   1778,    439,   1473,      9,   5830,  33728,\n",
            "            323,  47728,    198,      9,   4703,  11850,    323,   4788,  11850,\n",
            "           2082,    198,      9,  45565,   6170,    198,      9,  26230,   5865,\n",
            "            323,   6989,    271,  13556,  10172,   5829,  20506,    323,    264,\n",
            "           6683,   1052,    311,   7068,    279,   2082,     13,  47717,    649,\n",
            "           3350,    872,   1866,  20506,    323,  33483,    311,  52056,    279,\n",
            "           8066,   2082,    311,    872,   3230,   3966,    382,   1383,   1701,\n",
            "           9156,  10172,     11,  13707,    649,   3665,    892,    323,   8108,\n",
            "            279,   3392,    315,  59177,  11058,    814,   1205,    311,    656,\n",
            "             11,  10923,   1124,    311,   5357,    389,    810,   6485,    323,\n",
            "           7185,   9256,     13, 128009]], device='cuda:0')\n",
            "Answer:\n",
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is AutoGen in abstract?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "AutoGen is an open-source tool that generates boilerplate code for various programming languages, including C, C++, Java, Python, and others. It's designed to automate the creation of repetitive, mundane code that is often required in software development, such as:\n",
            "\n",
            "* Function signatures and prototypes\n",
            "* Error handling and exception handling code\n",
            "* Documentation comments\n",
            "* Utility functions and classes\n",
            "\n",
            "AutoGen uses templates and a configuration file to generate the code. Developers can write their own templates and configurations to tailor the generated code to their specific needs.\n",
            "\n",
            "By using AutoGen, developers can save time and reduce the amount of repetitive coding they need to do, allowing them to focus on more complex and interesting tasks.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the prompt\n",
        "# input_ids = tokenizer_loaded_fromHF.encode(\n",
        "#     \"What is AutoGen in abstract?\", return_tensors=\"pt\"\n",
        "# ).to(\"cuda\")\n",
        "# print(input_ids)\n",
        "chat = [{\"role\": \"user\", \"content\": \"What is AutoGen in abstract?\"}]\n",
        "input_ids = tokenizer_loaded_fromHF.apply_chat_template(chat, return_tensors ='pt').to(\"cuda\")\n",
        "print(input_ids)\n",
        "\n",
        "# Generate text\n",
        "result = model_loaded_fromHF.generate(input_ids, max_length=300)\n",
        "print(result)\n",
        "\n",
        "# Decode and print the generated text\n",
        "output_text = tokenizer_loaded_fromHF.decode(result[0])\n",
        "print(\"Answer:\")\n",
        "print(output_text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c2b15cb15754bd6b6fe52d59dccf005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97b58a7757b44d3fb06bb77454ac0880",
              "IPY_MODEL_d75370b7b8dd43d590eefb029a73e257",
              "IPY_MODEL_fdcdc1c38af942c9be6f0b64ae39310d"
            ],
            "layout": "IPY_MODEL_931677d3f9124466bcde9e2b0a8a253e"
          }
        },
        "97b58a7757b44d3fb06bb77454ac0880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a02b4c3a4c654d9e83bce5147c772dd7",
            "placeholder": "",
            "style": "IPY_MODEL_dd9baae3b97d4b95b817bb33dfc659f7",
            "value": "config.json:100%"
          }
        },
        "d75370b7b8dd43d590eefb029a73e257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa0b949157649b9ba3bc3757bb42c30",
            "max": 601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e92815890e984c508f20fdd11ef0c1d3",
            "value": 601
          }
        },
        "fdcdc1c38af942c9be6f0b64ae39310d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ca3cc1ab5c410485addb4b2e938715",
            "placeholder": "",
            "style": "IPY_MODEL_5768129d3b0c46c791f66fa62f2d279d",
            "value": "601/601[00:00&lt;00:00,52.7kB/s]"
          }
        },
        "931677d3f9124466bcde9e2b0a8a253e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02b4c3a4c654d9e83bce5147c772dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9baae3b97d4b95b817bb33dfc659f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa0b949157649b9ba3bc3757bb42c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92815890e984c508f20fdd11ef0c1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1ca3cc1ab5c410485addb4b2e938715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5768129d3b0c46c791f66fa62f2d279d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94412a9ee3794a26af42d69598a14e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7ac4400709b4eea966d735002482872",
              "IPY_MODEL_12a8117b3fb34048b328331877edd2ce",
              "IPY_MODEL_94cc1531235f4c31a9aacff6a826f330"
            ],
            "layout": "IPY_MODEL_e7544f2cadc54dff9c85b151da88af89"
          }
        },
        "b7ac4400709b4eea966d735002482872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ef9d7d48ab4591a9a12c6c78828a64",
            "placeholder": "",
            "style": "IPY_MODEL_bc134b3fb678409f99c63cfc0a47c252",
            "value": "model.safetensors.index.json:100%"
          }
        },
        "12a8117b3fb34048b328331877edd2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf527e99eb0495aa12843f6a96a8515",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4e3fc438640484e8373d048319ab2eb",
            "value": 23950
          }
        },
        "94cc1531235f4c31a9aacff6a826f330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a30e6edc134049a29b755efaccf94c",
            "placeholder": "",
            "style": "IPY_MODEL_9766f84c14144732b97bb11745661623",
            "value": "23.9k/23.9k[00:00&lt;00:00,2.25MB/s]"
          }
        },
        "e7544f2cadc54dff9c85b151da88af89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ef9d7d48ab4591a9a12c6c78828a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc134b3fb678409f99c63cfc0a47c252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf527e99eb0495aa12843f6a96a8515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e3fc438640484e8373d048319ab2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50a30e6edc134049a29b755efaccf94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9766f84c14144732b97bb11745661623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c19acded284cd29d666eab1167999a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_916823760e144866ac2e0c174d7154d8",
              "IPY_MODEL_5d53fbc5e9d14b4ea6b4b1276e3fd43e",
              "IPY_MODEL_06a1b14330064f3aae1cf1a88573f2d0"
            ],
            "layout": "IPY_MODEL_6a30a2db2fa5488fa8e896e10614e368"
          }
        },
        "916823760e144866ac2e0c174d7154d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da3c4f5fcf249fe855346bc48696737",
            "placeholder": "",
            "style": "IPY_MODEL_abefc04c6a6f44a48ed88ab4048ff84a",
            "value": "Fetching3files:0%"
          }
        },
        "5d53fbc5e9d14b4ea6b4b1276e3fd43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b9884786214b7aabd41c16c308fff0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_008a81a1f2244f9b94eb2b2eb43294e6",
            "value": 0
          }
        },
        "06a1b14330064f3aae1cf1a88573f2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c2af17a2de4ca1a115b7cb7e79da42",
            "placeholder": "",
            "style": "IPY_MODEL_29a5e9fd58fc44139156490d36134384",
            "value": "0/3[00:00&lt;?,?it/s]"
          }
        },
        "6a30a2db2fa5488fa8e896e10614e368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da3c4f5fcf249fe855346bc48696737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abefc04c6a6f44a48ed88ab4048ff84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19b9884786214b7aabd41c16c308fff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008a81a1f2244f9b94eb2b2eb43294e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47c2af17a2de4ca1a115b7cb7e79da42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a5e9fd58fc44139156490d36134384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3898571eeed04fbb87d043aa9a7efb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4ba719fff77423884e50551a77aa6b0",
              "IPY_MODEL_31dea37b2c4e4e9e89674104fefdad98",
              "IPY_MODEL_8d89fea593334ae6bedd0e29d0def50d"
            ],
            "layout": "IPY_MODEL_9f25c6310f94434ba5d83abd464c72ce"
          }
        },
        "f4ba719fff77423884e50551a77aa6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771f072a7dcb4da9b9b5dffda2d657f5",
            "placeholder": "",
            "style": "IPY_MODEL_62cd2d86cf2d4daebd789077c60f8ec6",
            "value": "model-00001-of-00003.safetensors:28%"
          }
        },
        "31dea37b2c4e4e9e89674104fefdad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7179b5e8924f0e853523346a23067a",
            "max": 4949453792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b64bbefef8df4ff58de3efc387a2f0a6",
            "value": 1373634560
          }
        },
        "8d89fea593334ae6bedd0e29d0def50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea4d33f5db644f6b3229236a8244a61",
            "placeholder": "",
            "style": "IPY_MODEL_9c368abbb7d5495287670e090ffe3299",
            "value": "1.37G/4.95G[00:58&lt;08:21,7.13MB/s]"
          }
        },
        "9f25c6310f94434ba5d83abd464c72ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "771f072a7dcb4da9b9b5dffda2d657f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62cd2d86cf2d4daebd789077c60f8ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7179b5e8924f0e853523346a23067a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64bbefef8df4ff58de3efc387a2f0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ea4d33f5db644f6b3229236a8244a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c368abbb7d5495287670e090ffe3299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e3d676a0bf498c87e67305513516c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e5a62645a984953855601f8ceffb375",
              "IPY_MODEL_02dd8de73885415d81ac2023bdccf8ee",
              "IPY_MODEL_241f7af51e4746e8b9397604ac670ef3"
            ],
            "layout": "IPY_MODEL_a5700e1af72d41209c1b5ab8b94b58ba"
          }
        },
        "4e5a62645a984953855601f8ceffb375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e0ae7a10d74cc69c89378526c6821e",
            "placeholder": "",
            "style": "IPY_MODEL_79e50b55b21a4fafa1acfd3ff675c1b1",
            "value": "model-00003-of-00003.safetensors:30%"
          }
        },
        "02dd8de73885415d81ac2023bdccf8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9218f5a996cf455caa4003914659dfe9",
            "max": 4546807800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_055311aced6b482483f9818f2316c491",
            "value": 1342177280
          }
        },
        "241f7af51e4746e8b9397604ac670ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff0de1de04c46008962f6dace820988",
            "placeholder": "",
            "style": "IPY_MODEL_859607149ba94d99bb3414da397a3f14",
            "value": "1.34G/4.55G[00:56&lt;18:54,2.83MB/s]"
          }
        },
        "a5700e1af72d41209c1b5ab8b94b58ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e0ae7a10d74cc69c89378526c6821e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e50b55b21a4fafa1acfd3ff675c1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9218f5a996cf455caa4003914659dfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055311aced6b482483f9818f2316c491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fff0de1de04c46008962f6dace820988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859607149ba94d99bb3414da397a3f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8501697c85b41d194e806dc5d48a6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_736b7c69ef754bd796f57e4fd0ca293d",
              "IPY_MODEL_fb297b9943c1460595988cb7c7bf32ee",
              "IPY_MODEL_6194bf8506c745279819d762ef0426fe"
            ],
            "layout": "IPY_MODEL_ce8754ea2cab46dd94a46937123fbc1d"
          }
        },
        "736b7c69ef754bd796f57e4fd0ca293d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f5b8151bd0450cadc63fbbefc27ef4",
            "placeholder": "",
            "style": "IPY_MODEL_4a6d7e7f667d4ec992ce46cb2c6e430b",
            "value": "model-00002-of-00003.safetensors:26%"
          }
        },
        "fb297b9943c1460595988cb7c7bf32ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99acb6506f943c8aefbdce5fa15bed4",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_612d2cc91ddd4eca8d4f02eb7cf0fc22",
            "value": 1321205760
          }
        },
        "6194bf8506c745279819d762ef0426fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b584a4bc8ad84019854250a85496c413",
            "placeholder": "",
            "style": "IPY_MODEL_a9f216aa4d28498bacdb6dd41cb9fb1e",
            "value": "1.32G/5.00G[00:58&lt;01:41,36.3MB/s]"
          }
        },
        "ce8754ea2cab46dd94a46937123fbc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f5b8151bd0450cadc63fbbefc27ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6d7e7f667d4ec992ce46cb2c6e430b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d99acb6506f943c8aefbdce5fa15bed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612d2cc91ddd4eca8d4f02eb7cf0fc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b584a4bc8ad84019854250a85496c413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f216aa4d28498bacdb6dd41cb9fb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}