# ğŸ¤– PÅ™Ã­prava dat pro Fine-tuning - TalkLike.LLM

> **ğŸ“š Navigace:** [ğŸ  HlavnÃ­ projekt](../README.md) | [ğŸ‹ï¸ Fine-tuning](../2_finetunning/README.md) | [ğŸ“Š Benchmarking](../3_benchmarking/README.md)

## ğŸ“‹ PÅ™ehled

Tento projekt vytvÃ¡Å™Ã­ dataset pro fine-tuning jazykovÃ©ho modelu, kterÃ½ napodobuje komunikaÄnÃ­ styl Andreje BabiÅ¡e. VytvoÅ™enÃ½ dataset obsahuje 1,500 QA pÃ¡rÅ¯ ve strukturovanÃ©m formÃ¡tu s charakteristickÃ½m stylem "babÃ­Å¡ovÅ¡tiny".

### ğŸ”„ VÃ½voj metodologie

#### PoÄÃ¡teÄnÃ­ pÅ™Ã­stup a jeho problÃ©my
**PrvnÃ­ pokus:** RuÄnÃ­ sbÄ›r dat
- StÃ¡hnuty vÅ¡echny projevy Andreje BabiÅ¡e z poslaneckÃ© snÄ›movny
- ZÃ­skÃ¡ny rozhovory z obdobÃ­ pÅ¯sobenÃ­ na ministerstvu financÃ­
- ShromÃ¡Å¾dÄ›ny ÄlÃ¡nky z bulvÃ¡rnÃ­ch plÃ¡tkÅ¯ (ParlamentnÃ­ listy)
- **ProblÃ©m:** Mix satirickÃ½ch vÃ½rokÅ¯ a pÅ™edpÅ™ipravenÃ½ch textÅ¯ byl nevyrovnanÃ½, konzistentnost nÃ¡zorÅ¯ byla problematickÃ¡ (data z roku 2013, 2017, 2021 jdou nÃ¡zorovÄ› proti sobÄ›)
- **VÃ½sledek:** RuÄnÃ­ tÅ™Ã­dÄ›nÃ­ se stalo neefektivnÃ­ a ÄasovÄ› nÃ¡roÄnÃ©

#### PÅ™echod k LLM-based metodÄ›
**DÅ¯vod zmÄ›ny:** LLM nedokÃ¡Å¾Ã­ zpracovat sloÅ¾itÄ›jÅ¡Ã­ zadÃ¡nÃ­ najednou
**Å˜eÅ¡enÃ­:** Rozklad procesu na menÅ¡Ã­, detailnÃ­ kroky
- Simplifikace zadÃ¡nÃ­
- Rozklad na tvorbu Å¡ablon a nÃ¡slednÃ© generovÃ¡nÃ­ datasetu
- PostupnÃ© zpracovÃ¡nÃ­ v dÃ¡vkÃ¡ch

## ğŸ¯ CÃ­l

VytvoÅ™it kvalitnÃ­ dataset pro fine-tuning, kterÃ½ zachovÃ¡vÃ¡:
- Mluvenou ÄeÅ¡tinu se slovensko-ÄeskÃ½mi odchylkami
- SpecifickÃ© rÃ©torickÃ© prvky a frÃ¡ze
- SatirickÃ½, emotivnÃ­ a sebestÅ™ednÃ½ tÃ³n
- AutentickÃ½ styl "babÃ­Å¡ovÅ¡tiny"

## ğŸ—ï¸ Architektura Å™eÅ¡enÃ­

### Workflow
1. **Å ablony** â†’ 2. **OdpovÄ›di** â†’ 3. **QA pÃ¡ry** â†’ 4. **SlouÄenÃ­** â†’ 5. **Validace**

### Struktura projektu
```
1_data_preparation/
â”œâ”€â”€ ğŸ“„ Skripty
â”‚   â”œâ”€â”€ generate_answers.py          # GenerovÃ¡nÃ­ odpovÄ›dÃ­ z Å¡ablon
â”‚   â”œâ”€â”€ generate_qa_dataset.py       # VytvoÅ™enÃ­ QA pÃ¡rÅ¯
â”‚   â”œâ”€â”€ dataset_merger.py           # SlouÄenÃ­ dat
â”‚   â”œâ”€â”€ data_quality_check.py       # Kontrola kvality
â”‚   â”œâ”€â”€ moderate_training_data.py   # Moderace obsahu
â”‚   â””â”€â”€ run_data_preparation.py     # HlavnÃ­ runner
â”œâ”€â”€ ğŸ“„ Å ablony a prompty
â”‚   â”œâ”€â”€ babis_templates_400.json    # 400 Å¡ablon vÃ½rokÅ¯
â”‚   â”œâ”€â”€ LLM.CreateAnswers.systemPrompt.md
â”‚   â”œâ”€â”€ LLM.CreateDialogue.systemPrompt.md
â”‚   â””â”€â”€ LLM.finetunning.systemPrompt.json
â”œâ”€â”€ ğŸ“„ Knihovny (lib/)
â”‚   â”œâ”€â”€ babis_dataset_generator.py
â”‚   â”œâ”€â”€ babis_dialog_generator.py
â”‚   â”œâ”€â”€ openai_cost_calculator.py
â”‚   â””â”€â”€ llm_cost_calculator.py
â””â”€â”€ ğŸ“„ VÃ½stupy (data/)
    â”œâ”€â”€ generated_batches/          # MezivÃ½stupy
    â”œâ”€â”€ final/                      # QA pÃ¡ry
    â””â”€â”€ all.jsonl                   # FinÃ¡lnÃ­ dataset
```

## ğŸš€ RychlÃ© spuÅ¡tÄ›nÃ­

### 1. Instalace
```bash
pip install -r requirements_datapreparation.txt
```

### 2. NastavenÃ­
```bash
# VytvoÅ™te .env soubor s OpenAI API klÃ­Äem
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

### 3. SpuÅ¡tÄ›nÃ­
```bash
python run_data_preparation.py
```

## ğŸ“‹ DetailnÃ­ kroky

### Krok 1: VytvoÅ™enÃ­ Å¡ablon
**Soubor:** `LLM.Outline.CreateTemplates.md`
- **Ãškol:** Vygenerovat 400 originÃ¡lnÃ­ch Å¡ablon vÃ½rokÅ¯
- **Model:** GPT-o3
- **VÃ½stup:** Å ablony s placeholdery pro rÅ¯znÃ© kategorie

**KlÃ­ÄovÃ© placeholdery:**
- `{tema}` - inflace, vÃ¡lka, dÅ¯chody, klima, oÄkovÃ¡nÃ­, danÄ›
- `{nepritel}` - Brusel, PirÃ¡ti, Fiala, novinÃ¡Å™i, opozice
- `{cinnost}` - makal, pomÃ¡hal lidem, budoval stÃ¡t, ruÅ¡il poplatky
- `{kritika}` - kradou, sabotujou nÃ¡s, jenom Å™eÄnÃ­
- `{emotivni_vyraz}` - to je Å¡Ã­lenÃ½!, kampÃ¡Ã¡Åˆ!, tragÃ©dyje!

### Krok 2: GenerovÃ¡nÃ­ odpovÄ›dÃ­
```bash
python generate_answers.py
```
- **Vstup:** 400 Å¡ablon z `babis_templates_400.json`
- **VÃ½stup:** 10 dÃ¡vek po 150 odpovÄ›dÃ­ch (celkem 1,500)
- **Pravidla:** 15% pravdÄ›podobnost jazykovÃ© chyby, mix 5 stylÅ¯

### Krok 3: VytvoÅ™enÃ­ QA datasetu
```bash
python generate_qa_dataset.py
```
- **Vstup:** OdpovÄ›di z kroku 2
- **VÃ½stup:** QA pÃ¡ry v JSONL formÃ¡tu

### Krok 4: SlouÄenÃ­ dat
```bash
python dataset_merger.py
```
- **Vstup:** QA pÃ¡ry z kroku 3
- **VÃ½stup:** `data/all.jsonl` - finÃ¡lnÃ­ dataset

### Krok 5: Kontrola kvality
```bash
python data_quality_check.py
```
- **Vstup:** FinÃ¡lnÃ­ dataset
- **VÃ½stup:** Report a vizualizace kvality

## ğŸ“Š Charakteristika datasetu

### Struktura dat
```json
{
  "messages": [
    {
      "role": "system",
      "content": "Jsi Andrej BabiÅ¡, ÄeskÃ½ politik a podnikatel..."
    },
    {
      "role": "user", 
      "content": "Pane BabiÅ¡i, jak hodnotÃ­te souÄasnou inflaci?"
    },
    {
      "role": "assistant",
      "content": "Hele, inflace je jak kdyÅ¾ krÃ¡va hraje na klavÃ­r!"
    }
  ]
}
```

### KlÃ­ÄovÃ© vlastnosti
- **PoÄet QA pÃ¡rÅ¯:** 1,500
- **Styl:** MluvenÃ¡ ÄeÅ¡tina s "babÃ­Å¡ovÅ¡tinou"
- **JazykovÃ© chyby:** 15% pravdÄ›podobnost slovenskÃ½ch odchylek
- **StylovÃ© variace:** 5 rÅ¯znÃ½ch stylÅ¯

### CharakteristickÃ© prvky
- **FrÃ¡ze:** "Hele", "To je skandÃ¡l!", "JÃ¡ makÃ¡m"
- **PÅ™irovnÃ¡nÃ­:** "jak kdyÅ¾ krÃ¡va hraje na klavÃ­r"
- **SlovenskÃ© odchylky:** "sme", "som", "makÃ¡me"
- **TÃ©mata:** Politika, ekonomika, rodina, podnikÃ¡nÃ­

## ğŸ’° NÃ¡klady a optimalizace

### KalkulÃ¡tor nÃ¡kladÅ¯
```python
from lib.openai_cost_calculator import OpenAICostCalculator

calculator = OpenAICostCalculator()
cost = calculator.estimate_batch_cost(input_text, output_text, "gpt-4o")
```

### Optimalizace
- **DÃ¡vkovÃ© zpracovÃ¡nÃ­:** Po 150 Å¡ablonÃ¡ch
- **CachovÃ¡nÃ­:** UklÃ¡dÃ¡nÃ­ surovÃ½ch odpovÄ›dÃ­
- **Validace:** Kontrola pÅ™ed uloÅ¾enÃ­m
- **LogovÃ¡nÃ­:** DetailnÃ­ sledovÃ¡nÃ­ procesu

## ğŸ” Kontrola kvality

### AutomatickÃ© kontroly
- âœ… Struktura konverzacÃ­
- âœ… StylovÃ© prvky

### Report kvality
- **Soubor:** `data_quality_report.json`
- **Vizualizace:** `data_quality_analysis.png`
- **Metriky:** ÃšspÄ›Å¡nost, distribuce stylÅ¯, dÃ©lky

## ğŸ› ï¸ PokroÄilÃ© moÅ¾nosti

### VlastnÃ­ Å¡ablony
```json
{
  "tema": ["inflace", "vÃ¡lka", "dÅ¯chody"],
  "nepritel": ["Brusel", "PirÃ¡ti", "Fiala"],
  "cinnost": ["makal", "pomÃ¡hal lidem", "budoval stÃ¡t"]
}
```

### Konfigurace modelÅ¯
```json
{
  "gpt-4o": {
    "name": "GPT-4 Optimized",
    "default": 1,
    "prices": {
      "batch": {"input": 1.25, "output": 5.00}
    }
  }
}
```

## ğŸš¨ Å˜eÅ¡enÃ­ problÃ©mÅ¯

### ÄŒastÃ© chyby
1. **OPENAI_API_KEY nenÃ­ nastaven**
   ```bash
   export OPENAI_API_KEY="your_key_here"
   ```

2. **ChybÄ›jÃ­cÃ­ soubory**
   ```bash
   ls babis_templates_400.json
   ls LLM.CreateAnswers.systemPrompt.md
   ```

3. **NedostateÄnÃ© kredity**
   - Zkontrolujte zÅ¯statek na OpenAI
   - PouÅ¾ijte levnÄ›jÅ¡Ã­ model v `availablemodels.json`

### DebugovÃ¡nÃ­
```bash
# SpuÅ¡tÄ›nÃ­ s detailnÃ­m vÃ½pisem
python -u generate_answers.py

# Kontrola logÅ¯
tail -f logs/llm_interaction_*.log
```

## ğŸ“ˆ VÃ½sledky a monitoring

### FinÃ¡lnÃ­ soubory
- `data/all.jsonl` - Dataset pro fine-tuning
- `data_quality_report.json` - Report kvality
- `data_quality_analysis.png` - Vizualizace
- `logs/data_preparation_*.json` - Logy

### Metriky kvality
- **ÃšspÄ›Å¡nost podpisÅ¯:** >95%
- **SlovenskÃ© odchylky:** 10-20%
- **CharakteristickÃ© frÃ¡ze:** >80%
- **PrÅ¯mÄ›rnÃ¡ dÃ©lka:** 50-150 znakÅ¯

### Logy a monitoring
- **UmÃ­stÄ›nÃ­:** `logs/`
- **FormÃ¡t:** JSON s timestampem
- **Obsah:** Prompt, odpovÄ›Ä, chyby, nÃ¡klady

## ğŸ”„ ÃšdrÅ¾ba a aktualizace

### PÅ™idÃ¡nÃ­ novÃ½ch Å¡ablon
1. Upravte `babis_templates_400.json`
2. SpusÅ¥te `generate_answers.py`
3. OvÄ›Å™te kvalitu pomocÃ­ `data_quality_check.py`

### Ãšprava stylu
1. Upravte systÃ©movÃ© prompty
2. Regenerujte dataset
3. Porovnejte kvalitu

### Optimalizace nÃ¡kladÅ¯
1. Zkontrolujte `availablemodels.json`
2. Upravte velikost dÃ¡vek
3. PouÅ¾ijte levnÄ›jÅ¡Ã­ modely

## âš ï¸ DÅ¯leÅ¾itÃ© poznÃ¡mky

### Moderace obsahu
Dataset byl zablokovÃ¡n OpenAI moderacÃ­ kvÅ¯li satirickÃ©mu obsahu. Chyba:
> "The job failed due to an invalid validation file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies"

### AlternativnÃ­ Å™eÅ¡enÃ­
- PouÅ¾itÃ­ lokÃ¡lnÃ­ch modelÅ¯ pro fine-tuning
- Ãšprava obsahu pro splnÄ›nÃ­ moderace
- PouÅ¾itÃ­ alternativnÃ­ch platform

## âœ… ShrnutÃ­

Projekt ÃºspÄ›Å¡nÄ› demonstroval kompletnÃ­ workflow pro vytvoÅ™enÃ­ fine-tuning datasetu pomocÃ­ LLM. KlÃ­ÄovÃ½m poznatkem bylo, Å¾e sloÅ¾itÃ© zadÃ¡nÃ­ je nutnÃ© rozdÄ›lit na menÅ¡Ã­, detailnÃ­ kroky.

**SilnÃ© strÃ¡nky:**
- ğŸ¯ ZamÄ›Å™enÃ­ na specifickÃ½ styl
- ğŸ’° OptimalizovanÃ© nÃ¡klady
- ğŸ” KompletnÃ­ validace
- ğŸ“Š DetailnÃ­ monitoring
- ğŸ› ï¸ SnadnÃ¡ ÃºdrÅ¾ba a rozÅ¡iÅ™itelnost

**Oblasti pro zlepÅ¡enÃ­:**
- Å˜eÅ¡enÃ­ moderace obsahu
- AlternativnÃ­ pÅ™Ã­stupy k fine-tuningu
