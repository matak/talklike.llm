# LoRA AdaptÃ©ry - SnadnÃ© pÅ™ipojenÃ­ k rÅ¯znÃ½m modelÅ¯m

> **ğŸ“š Navigace:** [ğŸ  HlavnÃ­ projekt](../README.md) | [ğŸ“Š PÅ™Ã­prava dat](../1_data_preparation/README.md) | [ğŸ‹ï¸ DetailnÃ­ dokumentace](README.md) | [ğŸ“ˆ Benchmarking](../3_benchmarking/README.md)

Tento dokument vysvÄ›tluje, jak vytvoÅ™it a pouÅ¾Ã­vat LoRA adaptÃ©ry z vaÅ¡eho datasetu, kterÃ© se dajÃ­ snadno pÅ™ipojit k rÅ¯znÃ½m modelÅ¯m.

## ğŸ¯ Co jsou LoRA adaptÃ©ry?

**LoRA (Low-Rank Adaptation)** je technika, kterÃ¡ umoÅ¾Åˆuje:
- âœ… **Malou velikost** (pÃ¡r MB vs GB celÃ©ho modelu)
- âœ… **SnadnÃ© pÅ™ipojenÃ­** k jakÃ©mukoli kompatibilnÃ­mu modelu
- âœ… **RychlÃ© naÄÃ­tÃ¡nÃ­** a pÅ™epÃ­nÃ¡nÃ­
- âœ… **MoÅ¾nost kombinovat** vÃ­ce adaptÃ©rÅ¯

## ğŸ“ Struktura souborÅ¯

```
2_finetunning/
â”œâ”€â”€ create_qlora_adapter.py    # VytvoÅ™enÃ­ QLoRA adaptÃ©ru
â”œâ”€â”€ test_adapter.py            # TestovÃ¡nÃ­ adaptÃ©ru
â”œâ”€â”€ finetune.py              # PÅ¯vodnÃ­ finetuning (uÅ¾ pouÅ¾Ã­vÃ¡ LoRA)
â””â”€â”€ adapters/                  # SloÅ¾ka pro uloÅ¾enÃ­ adaptÃ©rÅ¯
    â”œâ”€â”€ babis_adapter/         # VytvoÅ™enÃ½ adaptÃ©r
    â”œâ”€â”€ babis_adapter_config.json  # Konfigurace adaptÃ©ru
    â””â”€â”€ ...
```

## ğŸš€ VytvoÅ™enÃ­ adaptÃ©ru

### 1. ZÃ¡kladnÃ­ vytvoÅ™enÃ­ QLoRA adaptÃ©ru

```bash
python create_qlora_adapter.py \
    --base-model microsoft/DialoGPT-medium \
    --dataset ../data/final/all.jsonl \
    --output-dir ./adapters \
    --adapter-name babis_adapter \
    --epochs 3 \
    --batch-size 4
```

### 2. PokroÄilÃ© nastavenÃ­

```bash
python create_qlora_adapter.py \
    --base-model microsoft/DialoGPT-medium \
    --dataset ../data/final/all.jsonl \
    --output-dir ./adapters \
    --adapter-name babis_adapter_advanced \
    --r 16 \
    --lora-alpha 32 \
    --lora-dropout 0.05 \
    --max-length 2048 \
    --epochs 5 \
    --batch-size 2 \
    --learning-rate 1e-4
```

### 3. Parametry adaptÃ©ru

| Parametr | Popis | VÃ½chozÃ­ hodnota |
|----------|-------|-----------------|
| `--r` | LoRA rank (velikost adaptÃ©ru) | 8 |
| `--lora-alpha` | LoRA alpha (Å¡kÃ¡lovÃ¡nÃ­) | 16 |
| `--lora-dropout` | Dropout pro regularizaci | 0.1 |
| `--max-length` | MaximÃ¡lnÃ­ dÃ©lka sekvence | 2048 |
| `--epochs` | PoÄet epoch trÃ©novÃ¡nÃ­ | 3 |
| `--batch-size` | Velikost batch | 4 |
| `--learning-rate` | Learning rate | 2e-4 |

## ğŸ§ª TestovÃ¡nÃ­ adaptÃ©ru

### 1. InteraktivnÃ­ testovÃ¡nÃ­

```bash
# S konkrÃ©tnÃ­m modelem
python test_adapter.py \
    --base-model microsoft/DialoGPT-medium \
    --adapter ./adapters/babis_adapter

# Bez specifikace modelu (pouÅ¾ije se z konfigurace)
python test_adapter.py \
    --adapter ./adapters/babis_adapter
```

### 2. TestovÃ¡nÃ­ kompatibility

```bash
# Testuje kompatibilitu s rÅ¯znÃ½mi modely
python test_adapter.py \
    --adapter ./adapters/babis_adapter \
    --test-compatibility
```

### 3. PokroÄilÃ© testovÃ¡nÃ­

```bash
python test_adapter.py \
    --base-model gpt2 \
    --adapter ./adapters/babis_adapter \
    --device cuda \
    --max-length 1024 \
    --temperature 0.8
```

## ğŸ”„ PouÅ¾itÃ­ adaptÃ©ru s rÅ¯znÃ½mi modely

### KompatibilnÃ­ modely

AdaptÃ©r by mÄ›l bÃ½t kompatibilnÃ­ s tÄ›mito modely:
- `microsoft/DialoGPT-medium`
- `microsoft/DialoGPT-large`
- `gpt2`
- `gpt2-medium`
- `EleutherAI/gpt-neo-125M`
- `EleutherAI/gpt-neo-1.3B`

### PÅ™Ã­klad pouÅ¾itÃ­ v kÃ³du

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# NaÄtenÃ­ zÃ¡kladnÃ­ho modelu
base_model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")
tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")

# PÅ™ipojenÃ­ adaptÃ©ru
model = PeftModel.from_pretrained(base_model, "./adapters/babis_adapter")

# PouÅ¾itÃ­
response = model.generate(tokenizer.encode("Jak se mÃ¡Å¡?", return_tensors="pt"))
print(tokenizer.decode(response[0]))
```

## ğŸ“Š SrovnÃ¡nÃ­ pÅ™Ã­stupÅ¯

| Metoda | Velikost | Rychlost naÄÃ­tÃ¡nÃ­ | Kompatibilita | Kvalita |
|--------|----------|-------------------|---------------|---------|
| **Full Fine-tuning** | ~1-7 GB | PomalÃ¡ | SpecifickÃ¡ | VysokÃ¡ |
| **LoRA** | ~10-50 MB | RychlÃ¡ | Å irokÃ¡ | VysokÃ¡ |
| **QLoRA** | ~10-50 MB | RychlÃ¡ | Å irokÃ¡ | VysokÃ¡ |
| **Prompt Tuning** | ~1-10 MB | Velmi rychlÃ¡ | Å irokÃ¡ | StÅ™ednÃ­ |

## ğŸ›ï¸ Optimalizace adaptÃ©ru

### 1. Pro lepÅ¡Ã­ kvalitu
```bash
python create_qlora_adapter.py \
    --r 32 \
    --lora-alpha 64 \
    --epochs 5 \
    --learning-rate 1e-4
```

### 2. Pro menÅ¡Ã­ velikost
```bash
python create_qlora_adapter.py \
    --r 4 \
    --lora-alpha 8 \
    --epochs 2 \
    --learning-rate 3e-4
```

### 3. Pro rychlejÅ¡Ã­ trÃ©novÃ¡nÃ­
```bash
python create_qlora_adapter.py \
    --r 8 \
    --batch-size 8 \
    --epochs 1 \
    --learning-rate 5e-4
```

## ğŸ”§ Å˜eÅ¡enÃ­ problÃ©mÅ¯

### Chyba: "Target modules not found"
- AdaptÃ©r byl trÃ©novÃ¡n na jinÃ© architektuÅ™e modelu
- Zkuste jinÃ½ zÃ¡kladnÃ­ model nebo pÅ™etrÃ©nujte adaptÃ©r

### Chyba: "Out of memory"
- SniÅ¾te `--batch-size`
- PouÅ¾ijte `--device cpu`
- SniÅ¾te `--max-length`

### Chyba: "Model not compatible"
- Zkontrolujte, zda model podporuje LoRA
- Zkuste jinÃ½ zÃ¡kladnÃ­ model

## ğŸ“ˆ MonitorovÃ¡nÃ­ trÃ©novÃ¡nÃ­

AdaptÃ©r automaticky uklÃ¡dÃ¡:
- âœ… **Konfiguraci** (`adapter_config.json`)
- âœ… **VÃ¡hy adaptÃ©ru** (v adresÃ¡Å™i adaptÃ©ru)
- âœ… **AutomatickÃ© uklÃ¡dÃ¡nÃ­** checkpointÅ¯
- âœ… **Logy trÃ©novÃ¡nÃ­** v `/workspace/babis-finetuned/logs/`
- âœ… **Metriky trÃ©novÃ¡nÃ­** (pokud je povoleno logging)

## ğŸ¯ DoporuÄenÃ­

1. **ZaÄnÄ›te s menÅ¡Ã­m rankem** (`r=8`) a zvyÅ¡ujte podle potÅ™eby
2. **Testujte kompatibilitu** pÅ™ed pouÅ¾itÃ­m v produkci
3. **UklÃ¡dejte konfigurace** pro pozdÄ›jÅ¡Ã­ pouÅ¾itÃ­
4. **Experimentujte s rÅ¯znÃ½mi modely** pro nejlepÅ¡Ã­ vÃ½sledky

## ğŸ“š DalÅ¡Ã­ zdroje

- [PEFT dokumentace](https://huggingface.co/docs/peft)
- [LoRA paper](https://arxiv.org/abs/2106.09685)
- [QLoRA paper](https://arxiv.org/abs/2305.14314) 