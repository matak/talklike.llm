#!/usr/bin/env python3
"""
Test script pro ovƒõ≈ôen√≠ fin√°ln√≠ho ≈ôe≈°en√≠ Mistral system message
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import setup_environment

from transformers import AutoTokenizer
from data_utils import load_model_data, prepare_training_data

def test_mistral_final():
    """Testuje fin√°ln√≠ ≈ôe≈°en√≠ s apply_chat_template"""
    
    print("üîß Testuji fin√°ln√≠ ≈ôe≈°en√≠ Mistral system message...")
    
    # Naƒçten√≠ testovac√≠ch dat
    print("üìä Naƒç√≠t√°m testovac√≠ data...")
    conversations = load_model_data("data/all.jsonl")
    print(f"‚úÖ Naƒçteno {len(conversations)} konverzac√≠")
    
    # Naƒçten√≠ Mistral tokenizeru
    tokenizer = AutoTokenizer.from_pretrained(
        "mistralai/Mistral-7B-Instruct-v0.3",
        cache_dir='/workspace/.cache/huggingface/transformers',
        local_files_only=False,
        resume_download=True,
        force_download=False
    )
    
    print(f"‚úÖ Tokenizer naƒçten, vocab size: {len(tokenizer)}")
    
    # Test s fin√°ln√≠ funkc√≠
    print("\nüîß Testuji fin√°ln√≠ prepare_training_data...")
    training_data = prepare_training_data(conversations[:3], model_name="mistralai/Mistral-7B-Instruct-v0.3", tokenizer=tokenizer)
    print(f"‚úÖ P≈ôipraveno {len(training_data)} vzork≈Ø")
    
    # Kontrola prvn√≠ho vzorku
    if len(training_data) > 0:
        first_sample = training_data[0]
        print(f"\nüìù Prvn√≠ vzorek:")
        print(f"   Typ dat: {type(first_sample)}")
        print(f"   Kl√≠ƒçe: {list(first_sample.keys())}")
        
        if "text" in first_sample:
            text = first_sample["text"]
            print(f"   Text (prvn√≠ch 300 znak≈Ø): {text[:300]}...")
            print(f"   Celkov√° d√©lka: {len(text)} znak≈Ø")
            
            # Kontrola, zda obsahuje system message
            if "Jsi Andrej Babi≈°" in text:
                print("‚úÖ System message je p≈ô√≠tomna!")
            else:
                print("‚ùå System message chyb√≠!")
            
            # Kontrola, zda obsahuje Mistral form√°t
            if "[INST]" in text and "[/INST]" in text:
                print("‚úÖ Mistral form√°t je spr√°vn√Ω!")
            else:
                print("‚ùå Mistral form√°t chyb√≠!")
            
            # Kontrola, zda pou≈æ√≠v√° apply_chat_template
            if text.startswith("<s>[INST]"):
                print("‚úÖ Pou≈æ√≠v√° apply_chat_template!")
            else:
                print("‚ùå Nepou≈æ√≠v√° apply_chat_template!")
            
            # Test tokenizace
            try:
                tokenized = tokenizer(text, return_tensors="pt")
                print(f"‚úÖ Tokenizace √∫spƒõ≈°n√°, d√©lka: {tokenized['input_ids'].shape[1]} token≈Ø")
                
            except Exception as e:
                print(f"‚ùå Chyba p≈ôi tokenizaci: {e}")
    
    # Kontrola druh√©ho vzorku
    if len(training_data) > 1:
        second_sample = training_data[1]
        if "text" in second_sample:
            text = second_sample["text"]
            print(f"\nüìù Druh√Ω vzorek (prvn√≠ch 200 znak≈Ø): {text[:200]}...")
            
            # Kontrola, zda obsahuje system message
            if "Jsi Andrej Babi≈°" in text:
                print("‚úÖ System message je p≈ô√≠tomna!")
            else:
                print("‚ùå System message chyb√≠!")

if __name__ == "__main__":
    test_mistral_final() 