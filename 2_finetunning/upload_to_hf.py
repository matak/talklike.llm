#!/usr/bin/env python3
"""
Skript pro nahrÃ¡nÃ­ jiÅ¾ vygenerovanÃ©ho modelu na Hugging Face Hub
PouÅ¾ijte tento skript, pokud jste zapomnÄ›li pÅ™idat --push_to_hub do pÅ¯vodnÃ­ho pÅ™Ã­kazu
"""

import os
import argparse
from dotenv import load_dotenv
from huggingface_hub import login
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

def upload_model_to_hf(model_path, hub_model_id, token):
    """Nahraje model na Hugging Face Hub"""
    
    print(f"ğŸ“¤ NahrÃ¡vÃ¡m model z {model_path} na HF Hub...")
    print(f"ğŸ¯ Model ID: {hub_model_id}")
    
    # Kontrola existence modelu
    if not os.path.exists(model_path):
        print(f"âŒ Model neexistuje v cestÄ›: {model_path}")
        return False
    
    # Kontrola souborÅ¯ modelu
    required_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json']
    missing_files = []
    
    for file in required_files:
        if not os.path.exists(os.path.join(model_path, file)):
            missing_files.append(file)
    
    if missing_files:
        print(f"âš ï¸ ChybÃ­ soubory: {missing_files}")
        print("ğŸ“‹ DostupnÃ© soubory:")
        for file in os.listdir(model_path):
            print(f"  - {file}")
    
    try:
        # NaÄtenÃ­ modelu a tokenizeru
        print("ğŸ”§ NaÄÃ­tÃ¡m model...")
        model = AutoModelForCausalLM.from_pretrained(model_path)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        print("ğŸ“¤ NahrÃ¡vÃ¡m na HF Hub...")
        model.push_to_hub(hub_model_id, token=token)
        tokenizer.push_to_hub(hub_model_id, token=token)
        
        print(f"âœ… Model ÃºspÄ›Å¡nÄ› nahrÃ¡n!")
        print(f"ğŸŒ DostupnÃ½ na: https://huggingface.co/{hub_model_id}")
        return True
        
    except Exception as e:
        print(f"âŒ Chyba pÅ™i nahrÃ¡vÃ¡nÃ­: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='NahrÃ¡nÃ­ modelu na Hugging Face Hub')
    parser.add_argument('--model_path', type=str, required=True, 
                       help='Cesta k uloÅ¾enÃ©mu modelu (napÅ™. /workspace/babis-finetuned-final)')
    parser.add_argument('--hub_model_id', type=str, required=True,
                       help='NÃ¡zev modelu na HF Hub (napÅ™. username/babis-model)')
    parser.add_argument('--check_only', action='store_true',
                       help='Pouze zkontrolovat model bez nahrÃ¡vÃ¡nÃ­')
    
    args = parser.parse_args()
    
    # NaÄtenÃ­ promÄ›nnÃ½ch prostÅ™edÃ­
    load_dotenv()
    
    # Kontrola HF tokenu
    HF_TOKEN = os.getenv("HF_TOKEN")
    if not HF_TOKEN:
        print("âŒ HF_TOKEN nebyl nalezen v prostÅ™edÃ­!")
        print("ğŸ’¡ Nastavte HF_TOKEN v .env souboru nebo prostÅ™edÃ­")
        return
    
    # PÅ™ihlÃ¡Å¡enÃ­ na HF
    try:
        login(token=HF_TOKEN)
        print("âœ… Hugging Face login ÃºspÄ›Å¡nÃ½")
    except Exception as e:
        print(f"âŒ Chyba pÅ™i pÅ™ihlÃ¡Å¡enÃ­ na HF: {e}")
        return
    
    # Kontrola modelu
    print(f"ğŸ” Kontroluji model v: {args.model_path}")
    
    if not os.path.exists(args.model_path):
        print(f"âŒ Cesta neexistuje: {args.model_path}")
        print("\nğŸ’¡ MoÅ¾nÃ© cesty k modelu:")
        print("  - /workspace/babis-finetuned-final")
        print("  - /workspace/babis-mistral-finetuned-final")
        print("  - /workspace/[output_dir]-final")
        return
    
    # VÃ½pis obsahu adresÃ¡Å™e
    print(f"ğŸ“ Obsah adresÃ¡Å™e {args.model_path}:")
    try:
        for item in os.listdir(args.model_path):
            item_path = os.path.join(args.model_path, item)
            if os.path.isfile(item_path):
                size = os.path.getsize(item_path)
                print(f"  ğŸ“„ {item} ({size:,} B)")
            else:
                print(f"  ğŸ“ {item}/")
    except Exception as e:
        print(f"âš ï¸ Nelze ÄÃ­st obsah adresÃ¡Å™e: {e}")
    
    if args.check_only:
        print("\nâœ… Kontrola dokonÄena")
        return
    
    # NahrÃ¡nÃ­ modelu
    success = upload_model_to_hf(args.model_path, args.hub_model_id, HF_TOKEN)
    
    if success:
        print("\nğŸ‰ Model byl ÃºspÄ›Å¡nÄ› nahrÃ¡n na Hugging Face Hub!")
        print(f"ğŸ”— Odkaz: https://huggingface.co/{args.hub_model_id}")
        print("\nğŸ’¡ Pro pouÅ¾itÃ­ modelu:")
        print(f"   from transformers import AutoModelForCausalLM, AutoTokenizer")
        print(f"   model = AutoModelForCausalLM.from_pretrained('{args.hub_model_id}')")
        print(f"   tokenizer = AutoTokenizer.from_pretrained('{args.hub_model_id}')")
    else:
        print("\nâŒ NahrÃ¡vÃ¡nÃ­ selhalo")

if __name__ == "__main__":
    main() 