# RunPod.io Setup Guide

Tento n치vod v치s provede nastaven칤m fine-tuning prost콏ed칤 na RunPod.io.

## 游 Rychl칳 start

### 1. Vytvo콏en칤 podu

1. Jd캩te na [runpod.io](https://runpod.io)
2. Klikn캩te na "Deploy"
3. Vyberte template: `PyTorch 2.1.1`
4. Nastavte specifikace:
   - **GPU**: RTX 4090 nebo A100 (doporu캜eno)
   - **RAM**: Minim치ln캩 24GB
   - **Storage**: Minim치ln캩 50GB
   - **Network Volume**: Doporu캜eno pro persistentn칤 data

### 2. P콏ipojen칤 k podu

```bash
# SSH p콏ipojen칤
ssh root@your-pod-ip

# Nebo pou쬴jte webov칳 termin치l v RunPod UI
```

### 3. Instalace z치vislost칤

```bash
# Aktualizace syst칠mu
apt update && apt upgrade -y

# Instalace z치kladn칤ch bal칤캜k콢
apt install -y git wget curl htop

# Instalace Python z치vislost칤
pip install -r requirements_finetunning.txt
```

### 4. Nastaven칤 environment prom캩nn칳ch

```bash
# Vytvo콏en칤 .env souboru
cat > .env << EOF
HF_TOKEN=your_hf_token_here
EOF

# Nebo export prom캩nn칳ch
export HF_TOKEN=your_hf_token_here
```

### 5. Spu코t캩n칤 fine-tuning

```bash
# Klonov치n칤 repozit치콏e
git clone https://github.com/your-repo/talklike.llm.git
cd talklike.llm

# Spu코t캩n칤 fine-tuning
bash 2_finetunning/run_finetune.sh
```

## 游늵 Monitoring

### GPU Monitoring
```bash
# Sledov치n칤 GPU vyu쬴t칤
nvidia-smi -l 1

# Detailn칤 informace
nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv
```

### Disk Monitoring
```bash
# Sledov치n칤 m칤sta na disku
df -h

# Sledov치n칤 m칤sta v re치ln칠m 캜ase
watch -n 5 df -h
```

### Process Monitoring
```bash
# Sledov치n칤 proces콢
htop

# Sledov치n칤 Python proces콢
ps aux | grep python
```

## 游댢 Optimalizace

### Pro RTX 4090 (24GB VRAM)
```bash
python finetune.py \
    --model_name microsoft/DialoGPT-medium \
    --batch_size 2 \
    --max_length 1024
```

### Pro A100 (40GB VRAM)
```bash
python finetune.py \
    --model_name mistralai/Mistral-7B-Instruct-v0.2 \
    --batch_size 4 \
    --max_length 2048
```

### Pro men코칤 GPU
```bash
python finetune.py \
    --model_name microsoft/DialoGPT-small \
    --batch_size 1 \
    --max_length 512
```

## 游냍 콎e코en칤 probl칠m콢

### Out of Memory (OOM)
```bash
# Sni쬾e batch size
python finetune.py --batch_size 1

# Sni쬾e max_length
python finetune.py --max_length 512

# Pou쬴jte men코칤 model
python finetune.py --model_name microsoft/DialoGPT-small
```

### Nedostatek m칤sta na disku
```bash
# Vy캜i코t캩n칤 cache
rm -rf /root/.cache/huggingface
rm -rf /tmp/*

# Nebo pou쬴jte agresivn칤 vy캜i코t캩n칤
python finetune.py --aggressive_cleanup
```

### Pomal칠 stahov치n칤 modelu
```bash
# Pou쬴jte mirror
export HF_ENDPOINT=https://hf-mirror.com

# Nebo st치hn캩te model p콏edem
python -c "from transformers import AutoModel; AutoModel.from_pretrained('microsoft/DialoGPT-medium')"
```

## 游 Persistence dat

### Network Volume
```bash
# Mount network volume
mkdir -p /workspace
mount /dev/sdb1 /workspace

# Ulo쬰n칤 modelu na network volume
python finetune.py --output_dir /workspace/babis-finetuned
```

### Backup
```bash
# Z치lohov치n칤 modelu
tar -czf babis-model-backup.tar.gz /workspace/babis-finetuned

# Sta쬰n칤 z치lohy
scp root@your-pod-ip:babis-model-backup.tar.gz ./
```

## 游늳 V칳konnostn칤 tipy

### Optimalizace dataloader
```python
# V finetune.py
training_args = TrainingArguments(
    dataloader_num_workers=4,  # Zv칳코it podle CPU
    dataloader_pin_memory=True,
    dataloader_drop_last=True,
)
```

### Gradient checkpointing
```python
# Pro 칰sporu pam캩ti
training_args = TrainingArguments(
    gradient_checkpointing=True,
    gradient_accumulation_steps=4,
)
```

### Mixed precision
```python
# Pro rychlej코칤 tr칠nov치n칤
training_args = TrainingArguments(
    fp16=True,  # Pro NVIDIA GPU
    # bf16=True,  # Pro A100
)
```

## 游댕 U쬴te캜n칠 odkazy

- [RunPod.io](https://runpod.io/) - GPU hosting
- [Hugging Face](https://huggingface.co/) - Modely a tokeny
- [PyTorch](https://pytorch.org/) - Deep learning framework
- [PEFT](https://huggingface.co/docs/peft) - Parameter efficient fine-tuning 