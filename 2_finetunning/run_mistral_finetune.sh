#!/bin/bash

# Fine-tuning script pro Mistral model s daty Andreje BabiÅ¡e
# SpustitelnÃ½ na RunPod.io

set -e

echo "ğŸš€ SpouÅ¡tÃ­m fine-tuning pro Mistral model..."

# Kontrola, Å¾e jsme v root directory projektu
if [ ! -d "lib" ] || [ ! -d "data" ]; then
    echo "âŒ Skript musÃ­ bÃ½t spuÅ¡tÄ›n z root directory projektu!"
    echo "ğŸ’¡ SpusÅ¥te skript z adresÃ¡Å™e, kde jsou sloÅ¾ky 'lib' a 'data'"
    exit 1
fi

# NastavenÃ­ environment promÄ›nnÃ½ch
export HF_TOKEN="your_hf_token_here"
echo "HF_TOKEN=your_hf_token_here"

# SpuÅ¡tÄ›nÃ­ fine-tuning
cd 2_finetunning

python finetune.py \
    --data_path ../data/all.jsonl \
    --output_dir /workspace/mistral-babis-finetuned \
    --model_name mistralai/Mistral-7B-Instruct-v0.2 \
    --epochs 3 \
    --batch_size 1 \
    --learning_rate 1e-4 \
    --max_length 2048 \
    --aggressive_cleanup \
    --push_to_hub \
    --hub_model_id mistral-babis-lora

echo "âœ… Fine-tuning dokonÄen!" 