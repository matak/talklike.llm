#!/usr/bin/env python3
"""
Test script pro ovÄ›Å™enÃ­ opravy Mistral system message handling
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import setup_environment

from transformers import AutoTokenizer
from data_utils import load_model_data, prepare_training_data

def test_mistral_fix():
    """Testuje opravenÃ© Mistral formÃ¡tovÃ¡nÃ­"""
    
    print("ğŸ”§ Testuji opravenÃ© Mistral formÃ¡tovÃ¡nÃ­...")
    
    # NaÄtenÃ­ testovacÃ­ch dat
    print("ğŸ“Š NaÄÃ­tÃ¡m testovacÃ­ data...")
    conversations = load_model_data("data/all.jsonl")
    print(f"âœ… NaÄteno {len(conversations)} konverzacÃ­")
    
    # NaÄtenÃ­ Mistral tokenizeru
    tokenizer = AutoTokenizer.from_pretrained(
        "mistralai/Mistral-7B-Instruct-v0.3",
        cache_dir='/workspace/.cache/huggingface/transformers',
        local_files_only=False,
        resume_download=True,
        force_download=False
    )
    
    print(f"âœ… Tokenizer naÄten, vocab size: {len(tokenizer)}")
    
    # Test s opravenou funkcÃ­
    print("\nğŸ”§ Testuji opravenÃ© prepare_training_data...")
    training_data = prepare_training_data(conversations[:3], model_name="mistralai/Mistral-7B-Instruct-v0.3", tokenizer=tokenizer)
    print(f"âœ… PÅ™ipraveno {len(training_data)} vzorkÅ¯")
    
    # Kontrola prvnÃ­ho vzorku
    if len(training_data) > 0:
        first_sample = training_data[0]
        print(f"\nğŸ“ PrvnÃ­ vzorek:")
        print(f"   Typ dat: {type(first_sample)}")
        print(f"   KlÃ­Äe: {list(first_sample.keys())}")
        
        if "text" in first_sample:
            text = first_sample["text"]
            print(f"   Text (prvnÃ­ch 300 znakÅ¯): {text[:300]}...")
            print(f"   CelkovÃ¡ dÃ©lka: {len(text)} znakÅ¯")
            
            # Kontrola, zda obsahuje system message
            if "Jsi Andrej BabiÅ¡" in text:
                print("âœ… System message je pÅ™Ã­tomna!")
            else:
                print("âŒ System message chybÃ­!")
            
            # Kontrola, zda obsahuje Mistral formÃ¡t
            if "[INST]" in text and "[/INST]" in text:
                print("âœ… Mistral formÃ¡t je sprÃ¡vnÃ½!")
            else:
                print("âŒ Mistral formÃ¡t chybÃ­!")
            
            # Test tokenizace
            try:
                tokenized = tokenizer(text, return_tensors="pt")
                print(f"âœ… Tokenizace ÃºspÄ›Å¡nÃ¡, dÃ©lka: {tokenized['input_ids'].shape[1]} tokenÅ¯")
                
            except Exception as e:
                print(f"âŒ Chyba pÅ™i tokenizaci: {e}")
    
    # Kontrola druhÃ©ho vzorku
    if len(training_data) > 1:
        second_sample = training_data[1]
        if "text" in second_sample:
            text = second_sample["text"]
            print(f"\nğŸ“ DruhÃ½ vzorek (prvnÃ­ch 200 znakÅ¯): {text[:200]}...")
            
            # Kontrola, zda obsahuje system message
            if "Jsi Andrej BabiÅ¡" in text:
                print("âœ… System message je pÅ™Ã­tomna!")
            else:
                print("âŒ System message chybÃ­!")

if __name__ == "__main__":
    test_mistral_fix() 